[{"uri":"https://sharonng1029.github.io/fcj-fall2025-internship-report/5-workshop/5.4-frontend/5.4.1-amazonamplify/","title":"Amazon Amplify","tags":[],"description":"","content":"AMPLIFY 1. Method 1: Amplify Console (Recommended) Go to AWS Console → Amplify → Create new app Select Host web app Connect repository: GitHub/GitLab/Bitbucket ​​Authorize and select repo Build configuration: amplify.yml (already in the project):\nversion: 1 frontend: phases: preBuild: commands: - npm ci build: commands: - npm run build artifacts: baseDirectory: build files: - \u0026#39;**/*\u0026#39; cache: paths: - node_modules/**/* Environment Variables: VITE_API_BASE_URL: API Gateway URL VITE_COGNITO_USER_POOL_ID: User Pool ID VITE_COGNITO_CLIENT_ID: Client ID VITE_COGNITO_REGION: ap-southeast-1 Deploy and get Amplify URL 2. Method 2: Amplify CLI # Setting npm install -g @aws-amplify/cli # Configure AWS credentials amplifier configure # Initialize in project cd serverless-student-management-system-front-end amplify init # Add hosting amplify add hosting # Choose: Hosting with Amplify Console # Select: Manual deployment.deployment # Deploy amplify publish "},{"uri":"https://sharonng1029.github.io/fcj-fall2025-internship-report/5-workshop/5.3-backend/5.3.1-amazondynamodb/","title":"Amazon DynamoDB","tags":[],"description":"","content":"1. Amazon DynamoDB DynamoDB is a serverless NoSQL database that stores all system data:\nStudent information Classes, subjects Lecturers Scores Spring Boot backend system interacts with DynamoDB via:\nAWS SDK for Java 17 Spring Data DynamoDB or repository written by the team Presigned URL (upload documents, profiles) 1.1 DynamoDB table design (Single-Table Design) 1.1.1 Create Tables Table 1: Users\nTable name: student-management-users\rPartition key: id (String)\rSort key: email (String) Table 2: Classes\nTable name: student-management-classes\rPartition key: id (String) Table 3: Subjects\nTable name: student-management-subjects\rPartition key: id (String) Table 4: Notifications\nTable name: student-management-notifications\rPartition key: id (Number)\rSort key: sent_at (String) 1.1.2 Global Secondary Index (GSI) Configuration For the Users table, add GSI:\nIndex name: role-index Partition key: role (String) "},{"uri":"https://sharonng1029.github.io/fcj-fall2025-internship-report/5-workshop/5.1-workshop-overview/","title":"Introduction","tags":[],"description":"","content":"Serverless Student Management System (SMS) is a modern student management platform, built entirely on AWS serverless services. This system helps schools or small businesses easily manage, analyze, and interact with student data on a small to large scale without worrying about hardware infrastructure. Serverless components such as Lambda, DynamoDB, API Gateway, Amplify, ROUTE53, CloudFront, WAF help the system automatically scale, optimize costs, maintain high reliability and security.\nUsers operate through the web interface (React/Amplify), interact with dashboards, assignments, and scoreboards.\nAPI backend (REST) ensures access to student data, personalized access.\nNo need to manage traditional servers, the entire deployment and operation process – from storage, processing, to CI/CD – is integrated and automated through AWS services.\nWorkshop overview In this workshop, you will:\nInitialize and configure AWS core serverless services: DynamoDB, Lambda, API Gateway, Amplify, Cognito.\nBuild and test a student management system with features: CRUD dashboard, service quality monitoring.\nExperience the DevOps CI/CD process automated from GitLab to AWS Pipeline, test and demo live the system.\nApply practical knowledge to real lessons or similar projects, easily expand to mobile environments or integrate advanced AI.\n"},{"uri":"https://sharonng1029.github.io/fcj-fall2025-internship-report/3-blogstranslated/3.1-blog1/","title":"Blog 1","tags":[],"description":"","content":"Introducing Strands Agents, an Open Source AI Agents SDK by Clare Liguori | on 16 MAY 2025 | in Announcements, Artificial Intelligence, Geneative AI, Open Source | Permalink | Comments | Shared\nToday I am happy to announce we are releasing Strands Agents. Strands Agents is an open source SDK that takes a model-driven approach to building and running AI agents in just a few lines of code. Strands scales from simple to complex agent use cases, and from local development to deployment in production. Multiple teams at AWS already use Strands for their AI agents in production, including Amazon Q Developer, AWS Glue, and VPC Reachability Analyzer. Now, I’m thrilled to share Strands with you for building your own AI agents.\nCompared with frameworks that require developers to define complex workflows for their agents, Strands simplifies agent development by embracing the capabilities of state-of-the-art models to plan, chain thoughts, call tools, and reflect. With Strands, developers can simply define a prompt and a list of tools in code to build an agent, then test it locally and deploy it to the cloud. Like the two strands of DNA, Strands connects two core pieces of the agent together: the model and the tools. Strands plans the agent’s next steps and executes tools using the advanced reasoning capabilities of models. For more complex agent use cases, developers can customize their agent’s behavior in Strands. For example, you can specify how tools are selected, customize how context is managed, choose where session state and memory are stored, and build multi-agent applications. Strands can run anywhere and can support any model with reasoning and tool use capabilities, including models in Amazon Bedrock, Anthropic, Ollama, Meta, and other providers through LiteLLM.\nStrands Agents is an open community, and we’re excited that several companies are joining us with support and contributions including Accenture, Anthropic, Langfuse, mem0.ai, Meta, PwC, Ragas.io, and Tavily. For instance, Anthropic has already contributed support in Strands for using models through the Anthropic API, and Meta contributed support for Llama models through Llama API. Join us GitHub to get started with Strands Agents!\nOur journey building agents I primarily work on Amazon Q Developer, a generative AI-powered assistant for software development. My team and I started building AI agents in early 2023, around when the original ReAct (Reasoning and Acting) was published. This paper showed that large language models could reason, plan, and take actions in their environment. For example, LLMs could reason that they needed to make an API call to complete a task and then generate the inputs needed for that API call. We then realized that large language models could be used as agents to complete many types of tasks, including complex software development and operational troubleshooting.\nAt that time, LLMs weren’t typically trained to act like agents. They were often trained primarily for natural language conversation. Successfully using an LLM to reason and act required complex prompt instructions on how to use tools, parsers for the model’s responses, and orchestration logic. Simply getting LLMs to reliably produce syntactically correct JSON was a challenge at the time! To prototype and deploy agents, my team and I relied on a variety of complex agent framework libraries that handled the scaffolding and orchestration needed for the agents to reliably succeed at their tasks with these earlier models. Even with these frameworks, it would take us months of tuning and tweaking to get an agent ready for production.\nSince then, we’ve seen a dramatic improvement in large language models’ abilities to reason and use tools to complete tasks. We realized that we no longer needed such complex orchestration to build agents, because models now have native tool-use and reasoning capabilities. In fact, some of the agent framework libraries we had been using to build our agents started to get in our way of fully leveraging the capabilities of newer LLMs. Even though LLMs were getting dramatically better, those improvements didn’t mean we could build and iterate on agents any faster with the frameworks we were using. It still took us months to make an agent production-ready.\nWe started building Strands Agents to remove this complexity for our teams in Q Developer. We found that relying on the latest models’ capabilities to drive agents significantly reduced our time to market and improved the end user experience, compared to building agents with complex orchestration logic. Where it used to take months for Q Developer teams to go from prototype to production with a new agent, we’re now able to ship new agents in days and weeks with Strands.\nCore concepts of Strands Agents The simplest definition of an agent is a combination of three things: 1) a model, 2) tools, and 3) a prompt. The agent uses these three components to complete a task, often autonomously. The agent\u0026rsquo;s task could be to answer a question, generate code, plan a vacation, or optimize your financial portfolio. In a model-driven approach, the agent uses the model to dynamically direct its own steps and to use tools in order to accomplish the specified task.\nTo define an agent with the Strands Agents SDK, you define these three components in code:\nModel: Strands offers flexible model support. You can use any model in Amazon Bedrock that supports tool use and streaming, a model from Anthropic’s Claude model family through the Anthropic API, a model from the Llama model family via Llama API, Ollama for local development, and many other model providers such as OpenAI through LiteLLM. You can additionally define your own custom model provider with Strands. Tools:You can choose from thousands of published Model Context Protocol (MCP) servers to use as tools for your agent. Strands also provides 20 công cụ ví dụ dựng sẵn, including tools for manipulating files, making API requests, and interacting with AWS APIs. You can easily use any Python function as a tool, by simply using the Strands @tool decorator. Prompt: You provide a natural language prompt that defines the task for your agent, such as answering a question from an end user. You can also provide a system prompt that provides general instructions and desired behavior for the agent. An agent interacts with its model and tools in a loop until it completes the task provided by the prompt. This agentic loop is at the core of Strands’ capabilities. The Strands agentic loop takes full advantage of how powerful LLMs have become and how well they can natively reason, plan, and select tools. In each loop, Strands invokes the LLM with the prompt and agent context, along with a description of your agent’s tools. The LLM can choose to respond in natural language for the agent’s end user, plan out a series of steps, reflect on the agent’s previous steps, and/or select one or more tools to use. When the LLM selects a tool, Strands takes care of executing the tool and providing the result back to the LLM. When the LLM completes its task, Strands returns the agent’s final result .\nIn Strands’ model-driven approach, tools are key to how you customize the behavior of your agents. For example, tools can retrieve relevant documents from a knowledge base, call APIs, run Python logic, or just simply return a static string that contains additional model instructions. Tools also help you achieve complex use cases in a model-driven approach, such as with these Strands Agents example pre-built tools:\nRetrieve tool: This tool implements semantic search using Amazon Bedrock Knowledge Bases. eyond retrieving documents, the retrieve tool can also help the model plan and reason by retrieving other tools using semantic search. For example, one internal agent at AWS has over 6,000 tools to select from! Models today aren’t capable of accurately selecting from quite that many tools. Instead of describing all 6,000 tools to the model, the agent uses semantic search to find the most relevant tools for the current task and describes only those tools to the model. You can implement this pattern by storing many tool descriptions in a knowledge base and letting the model use the retrieve tool to retrieve a subset of relevant tools for the current task. Thinking tool: This tool prompts the model to do deep analytical thinking through multiple cycles, enabling sophisticated thought processing and self-reflection as part of the agent. In the model-driven approach, modeling thinking as a tool enables the model to reason about if and when a task needs deep analysis. Multi-agent tools như like the workflow, graph, and swarm tools: For complex tasks, Strands can orchestrate across multiple agents in a variety of multi-agent collaboration patterns. By modeling sub-agents and multi-agent collaboration as tools, the model-driven approach enables the model to reason about if and when a task requires a defined workflow, graph, or swarm of sub-agents. Strands support for the Agent2Agent (A2A) protocol for multi-agent applications is coming soon. Get started with Strands Agents Let’s walk through an example of building an agent with the Strands Agents SDK. As has long been said, naming things is one of the hardest problems in computer science. Naming an open source project is no exception! To help us brainstorm potential names for the Strands Agents project, I built a naming AI assistant using Strands. In this example, you will use Strands to build a naming agent using a default model in Amazon Bedrock, an MCP server, and a pre-built Strands tool.\nCreate a file named agent.py with this code:\nfrom strands import Agent from strands.tools.mcp import MCPClient from strands_tools import http_request from mcp import stdio_client, StdioServerParameters # Define a naming-focused system prompt NAMING_SYSTEM_PROMPT = \u0026#34;\u0026#34;\u0026#34; You are an assistant that helps to name open source projects. When providing open source project name suggestions, always provide one or more available domain names and one or more available GitHub organization names that could be used for the project. Before providing your suggestions, use your tools to validate that the domain names are not already registered and that the GitHub organization names are not already used. \u0026#34;\u0026#34;\u0026#34; # Load an MCP server that can determine if a domain name is available domain_name_tools = MCPClient(lambda: stdio_client( StdioServerParameters(command=\u0026#34;uvx\u0026#34;, args=[\u0026#34;fastdomaincheck-mcp-server\u0026#34;]) )) # Use a pre-built Strands Agents tool that can make requests to GitHub # to determine if a GitHub organization name is available github_tools = [http_request] with domain_name_tools: # Define the naming agent with tools and a system prompt tools = domain_name_tools.list_tools_sync() + github_tools naming_agent = Agent( system_prompt=NAMING_SYSTEM_PROMPT, tools=tools ) # Run the naming agent with the end user\u0026#39;s prompt naming_agent(\u0026#34;I need to name an open source project for building AI agents.\u0026#34;) You will need a GitHub personal access token to run the agent. Set the environment variable GITHUB_TOKEN with the value of your GitHub token. You will also need Bedrock model access for Anthropic Claude 3.7 Sonnet in us-west-2, and AWS credentials configured locally.\nNow run your agent:\npip install strands-agents strands-agents-tools python -u agent.py You should see output from the agent similar to this snippet:\nBased on my checks, here are some name suggestions for your open source AI agent building project: ## Project Name Suggestions: 1. **Strands Agents** - Available domain: strandsagents.com - Available GitHub organization: strands-agents You can easily start building new agents today with the Strands Agents SDK in your favorite AI-assisted development tool. To help you quickly get started, we published a Strands MCP server to use with any MCP-enabled development tool, such as the Q Developer CLI or Cline. For the Q Developer CLI, use the following example to add the Strands MCP server to the CLI’s MCP Configuration. You can see more configuration examples on GitHub.\n{ \u0026#34;mcpServers\u0026#34;: { \u0026#34;strands\u0026#34;: { \u0026#34;command\u0026#34;: \u0026#34;uvx\u0026#34;, \u0026#34;args\u0026#34;: [\u0026#34;strands-agents-mcp-server\u0026#34;] } } } Deploy Strands Agents in production Running agents in production is a key tenet for the design of Strands. The Strands Agents project includes a (deployment toolkit) with a set of reference implementations to help you take your agents to production. Strands is flexible enough to support a variety of architectures in production. You can use Strands to build conversational agents as well as agents that are triggered by events, run on a schedule, or run continuously. You can deploy an agent built with the Strands Agents SDK as a monolith, where both the agentic loop and the tool execution run in the same environment, or as a set of microservices. I will describe four agent architectures that we use internally at AWS with Strands Agents.\nThe following diagram shows an agent architecture with Strands running entirely locally in a user’s environment through a client application. The example command line tool GitHub follows this architecture for a CLI-based AI assistant for building agents.\nThe next diagram shows an architecture where the agent and its tools are deployed behind an API in production. We have provided reference implementations on GitHub for how to deploy agents built with the Strands Agents SDK behind an API on AWS, using AWS Lambda, AWS Fargate, or Amazon Elastic Compute Cloud (Amazon EC2).\nYou can separate concerns between the Strands agentic loop and tool execution by running them in separate environments. The following diagram shows an agent architecture with Strands where the agent invokes its tools via API, and the tools run in an isolated backend environment separate from the agent’s environment. For example, you could run your agent’s tools in Lambda functions, while running the agent itself in a Fargate container.\nYou can also implement a return-of-control pattern with Strands, where the client is responsible for running tools. This diagram shows an agent architecture where an agent built with the Strands Agents SDK can use a mix of tools that are hosted in a backend environment and tools that run locally through a client application that invokes the agent.\nRegardless of your exact architecture, observability of your agents is important for understanding how your agents are performing in production. Strands provides instrumentation for collecting agent trajectories and metrics from production agents. Strands uses OpenTelemetry (OTEL) to emit telemetry data to any OTEL-compatible backend for visualization, troubleshooting, and evaluation. Strands’ support for distributed tracing enables you to track requests through different components in your architecture, in order to paint a complete picture of agent sessions.\nJoin the Strands Agents community Strands Agents is an open source project licensed under the Apache License 2.0. We are excited to now build Strands in the open with you. We welcome contributions to the project, including adding support for additional providers’ models and tools, collaborating on new features, or expanding the documentation. If you find a bug, have a suggestion, or have something to contribute, join us on GitHub.\nTo learn more about Strands Agents and to start building your first AI agent with Strands, visit our documentation.\nClare Liguori Clare Liguori is a Senior Principal Software Engineer for AWS Agentic AI. She focuses on re-imagining how applications are built and how productive developers can be when their tools are powered by generative AI and AI agents, as part of Amazon Q Developer. "},{"uri":"https://sharonng1029.github.io/fcj-fall2025-internship-report/3-blogstranslated/3.2-blog2/","title":"Blog 2","tags":[],"description":"","content":"Introducing managed accounting for AWS Parallel Computing Service by Ramin Torabi, Nick Ihli, and Tarun Mathur | on 15 MAY 2025 | in AWS Parallel Computing Service , High Performance Computing, Technical How-to | Permalink | Share\nThis post was contributed by Ramin Torabi and Tarun Mathur from AWS, and Nick Ihli from SchedMD.\nAWS Parallel Computing Service (PCS) is a managed service that makes it easier for you to run and scale your high performance computing (HPC) workloads on AWS using Slurm. Organizations running HPC clusters want to monitor resource utilization, enforce resource limits, and manage access-control to specific capacity across users and projects. They want to understand “who did what” in their cluster for leadership reporting, capacity planning, and budgeting purposes. PCS now supports accounting, a Slurm feature that enables these activities in a cluster. PCS manages the accounting database for the cluster, so that you don’t have to setup and manage a separate accounting database.\nIn this post, we’ll show you how this works, and point you to some actual use cases you can try yourself.\nSetup Follow these steps to enable accounting in PCS:\nCreate a new PCS cluster with Slurm 24.11 or later, opt in to the accounting feature, and configure optional accounting parameters as shown in Figure-1. Once the cluster status is Active, verify accounting is enabled and review configured parameters in the cluster details console page. Configure and connect to a login node as described here, and perform accounting commands using the root account. Figure 1 – The “Create Cluster” console experience where you can enable and configure accounting. Use Case 1: Attribute Usage to Projects Organizations want visibility into resource usage for each project or department so they can internally chargeback relevant cost centers. To do so, they need to track and attribute usage at different levels. One scenario in Figure-2:\nCreate 3 users, create accounts proj\\_physics and proj\\_chemistry, and add users to accounts with the sacctmgr function. An ‘account’ is an organizational unit used to group and manage users. Each user submits a single job attributed to the proj\\_physics account with the –account= \u0026lt;account\\_name\u0026gt; flag. Validate that those jobs are attributed to the correct account proj_physics by looking up accounting data with the sacct function. Validate that user1 is a member of both proj\\_physics and proj\\_chemistry accounts. Figure 2 – Example workflow of project attribution. Use Case 2: Enforce Limits Organizations want to set constraints on particular users or projects so one party isn’t hoarding resources. One scenario:\nSet a limit of 6000 CPU minutes (100 CPU hours) for a particular user with the command sacctmgr modify user username set GrpTRESRunMins=cpu=6000 Run the validation in Figure-3 to check the limit was set correctly. Let’s assume the user has already used 95 CPU hours, and then tries to submit a job that would exceed their quota: sbatch --cpus-per-task=10 --time=1:00:00 myjob.sh. This job requests 10 CPUs for 1 hour, which would use 10 CPU hours, exceeding the remaining 5 CPU hours in the user’s quota. The job submission will fail and the user will see the error in Figure-4. The user can then submit a smaller job of say 4 CPU hours which would be accepted as it fits within the remaining quota: sbatch --cpus-per-task=2 --time=2:00:00 [smalljob.sh](http://smalljob.sh) Figure 3 – Example check to identify a limit was set correctly. Figure 4 – Example output of an error due to a job submission that exceeds user limit. Use Case 3: Generate Usage Reports Organizations want usage report summaries to assess their resource utilization and plan future capacity allocations. One scenario:\nQuery all jobs run in your cluster in the past week with the command sacct --starttime=$(date -d \u0026#34;7 days ago\u0026#34; +%Y-%m-%d) -- format=\u0026#34;JobID,User,JobName,Partition,Account,AllocCPUS,State,ExitCode\u0026#34; The example output in Figure-5 shows the unique JobID of each job submission, which user submitted it, which partition (queue) the job was submitted from, how many CPUs were used to run that job, and the status of that job. Analyze that data to identify broader trends in your cluster. Note that most submitted jobs were completed, yet job 1236 failed, job 1238 got cancelled, and job 1240 is a large running job with 16 allocated CPUs. Query utilization over a single month with the command sreport cluster AccountUtilizationByUser start=2025-04-01 end=2025-04-30 -t percent format=\u0026#34;Accounts,Login,Proper,Used\u0026#34; The example output in Figure-6 shows cluster utilization by project and user. Analyze these trends to identify adjustments to your allocation strategy across users and accounts. Identify whether it is fair that project\\_a01 and particularly user1 are hoarding 42% of resources over the month. Query top users over the prior month with the command sreport user topusage start=2025-03-01 end=2025-03-31 The example output in Figure-7 lists the top users by CPU minutes in the cluster. Note that user1 continues to be the largest user in the prior month. Figure 5 – Weekly Jobs report using sacct command. Figure 6 – Monthly cluster utilization report using sreport command. Figure 7 – Monthly top users report using sreport command. Use Case 4: Identify Job Issues Individual users want usage report summaries to identify and remediate job failures. One scenario:\nUser checks their failed jobs in the past week with the command sacct -u username --starttime=$(date -d \u0026#34;7 days ago\u0026#34; +%Y-%m-%d) --format=\u0026#34;JobID,JobName,State,ExitCode,Start,End,MaxRSS,MaxVMSize,Comment\u0026#34; The example output in Figure-8 helps the user identify that two jobs have failed due to high memory usage, and the third job succeeded as it was more memory efficient (2800MB used). The user reviews the job scripts for both cnn_test and bert_run and identifies the root cause – the scripts are not requesting enough memory. The user can then evaluate whether they want to modify the scripts to request sufficient memory and re-submit those two jobs. Figure 8 – Weekly job failures report for a particular user using sacctcommand. For more accounting use cases see SchedMD documentation for the sacctmgr, sacct, and sreport commands.\nPricing Enabling accounting will incur two additional charges – an hourly accounting usage fee that varies by cluster controller size chosen, and an accounting storage fee that is billed in per GB-month increments. The accounting usage fee is billed while accounting is enabled on your cluster, and the accounting storage fee scales based on the number of accounting records stored (configurable via the Default Purge Time parameter explained in the documentation). More details are on the PCS pricing page.\nConclusion In this post, we showed how you can leverage the managed accounting feature in AWS Parallel Computing Service to monitor cluster usage on your cluster. Get started today by visiting the AWS PCS management console. Let us know what you think!\nTAGS: HPC\nRamin Torabi\nRamin Torabi is a Senior Specialist HPC Solutions Architect at AWS. He enables customers in central Europe architecting their solutions around HPC. He has more than 15 years of experience with HPC and CAE especially in the Automotive, Aerospace, and other manufacturing industries. Ramin received a \u0026ldquo;Dr. rer. nat.\u0026rdquo; (PhD) in theoretical nuclear structure physics from the Technical University of Darmstadt in 2009. Nick Ihli\nNick Ihli is the Director of Solutions Engineering at SchedMD. He\u0026rsquo;s been focused on HPC schedulers for 20 years and specifically has expertise with running Slurm in the cloud. He loves helping customers become more efficient with Slurm in HPC and AI environments. When he\u0026rsquo;s not talking Slurm, you can find him coaching youth on the football field or basketball court. Tarun Mathur\nTarun Mathur is a Product Manager covering HPC and scientific computing at AWS. His goal is for customers running HPC workloads to have a smooth orchestration experience on AWS. Outside work, he enjoys Brazilian jiu-jitsu, mountaineering, and searching for the best rooftop bar. "},{"uri":"https://sharonng1029.github.io/fcj-fall2025-internship-report/3-blogstranslated/3.3-blog3/","title":"Blog 3","tags":[],"description":"","content":"Simplify AWS AppSync Events integration with Powertools for AWS Lambda by Ana Falcao and Leandro Cavalcante Damascena | on 14 MAY 2025 | in AWS AppSync, AWS Lambda, Developer Tools, Technical How-to | Permalink | Share\nReal-time capabilities have become essential in modern applications, where users expect immediate updates and interactive experiences. Whether you’re building chat applications, live dashboards, gaming leaderboards, or IoT systems, AWS AppSync Events enables these real-time features through WebSocket APIs, allowing you to build scalable and performant real-time applications, without worrying about scale or connection management.\nPowertools for AWS Lambda is a developer toolkit that includes observability, batch processing, AWS Systems Manager Store Parameter Store integration, idempotency, feature flags, Amazon CloudWatch Metrics, structured logging, and more. Powertools for AWS now supports AppSync Events through the new AppSyncEventsResolver, available in Python, TypeScript, and .NET. This new feature enhances the development experience with capabilities designed to help you focus on your business logic. The AppSyncEventsResolver provides a simple and consistent interface for processing events, with built-in support for common patterns such as filtering, transforming, and routing events.\nIn this post, you will see examples in TypeScript, but you can use the same functionality in Python and .NET functions using Powertools for AWS (Python) and Powertools for AWS (.NET).\nFigure 1 Real-time event handling architecture using AWS AppSync, Lambda, and Powertools. In this post, you’ll learn how to:\nSet up event handlers using the AppSyncEventsResolver Implement different event processing patterns for optimal performance Use pattern-based routing to organize your event handlers Leverage built-in features for common use cases Getting Started The AppSyncEventsResolver provides a simple, declarative way to handle AppSync Events in your AWS Lambda function. The event resolver allows you to listen for PUBLISH and SUBSCRIBE events. PUBLISH events occur when clients send messages to a channel, while SUBSCRIBE events happen when clients attempt to subscribe to a channel. You can register handlers for different namespaces and channels to manage your event-driven communications.\nLet’s explore how to get started and the core features that will enhance your development experience. Here’s a basic example of how to set up the AppSyncEventsResolver:\nimport { AppSyncEventsResolver, UnauthorizedException, } from \u0026#39;@aws-lambda-powertools/event-handler/appsync-events\u0026#39;; // Types for our message handling type ChatMessage = { userId: string; content: string; } // Simple authorization check const isAuthorized = (path: string, userId?: string): boolean =\u0026gt; { // check against your authorization system if (path.startsWith(\u0026#39;/chat/private\u0026#39;) \u0026amp;\u0026amp; !userId) { return false; } return true; }; // Message processing logic const processMessage = async (payload: ChatMessage) =\u0026gt; { // - Validate message content // - Store in database // - Enrich with additional data return { ...payload, timestamp: new Date().toISOString() }; }; const app = new AppSyncEventsResolver(); // Handle publish events for a specific channel app.onPublish(\u0026#39;/chat/general\u0026#39;, async (payload: ChatMessage) =\u0026gt; { // Process and return the message return processMessage(payload); }); // Handle subscription events for all channels app.onSubscribe(\u0026#39;/\\*\u0026#39;, async (info) =\u0026gt; { const { channel: { path }, request, } = info; // Perform access control checks if (!isAuthorized(path, userId)) { throw new UnauthorizedException(`not allowed to subscribe to ${path}`); } return true; }); export const handler = async (event, context) =\u0026gt; app.resolve(event, context); The AppSyncEventsResolver class takes care of parsing the incoming event data and invoking the appropriate handler method based on the event type. Let’s break down what’s happening:\nPattern-based Routing The AppSyncEventsResolver uses an intuitive pattern-based routing system that allows you to organize your event handlers based on channel paths. You can:\nHandle specific channels (/chat/general) Use wildcards for namespaces (/chat/*) Create global catch-all handlers (/*) import { AppSyncEventsResolver } from \u0026#39;@aws-lambda-powertools/event-handler/appsync-events\u0026#39;; const app = new AppSyncEventsResolver(); // Specific channel handler app.onPublish(\u0026#39;/notifications/alerts\u0026#39;, async (payload) =\u0026gt; { // your logic here }); // Handle all channels in the notifications namespace app.onPublish(\u0026#39;/notifications/\\*\u0026#39;, async (payload) =\u0026gt; { // your logic here }); // Global catch-all for unhandled channels app.onPublish(\u0026#39;/\\*\u0026#39;, async (payload) =\u0026gt; { // your logic here }); export const handler = async (event, context) =\u0026gt; app.resolve(event, context); The most general catch-all handler is /*, which will match any namespace and channel, while /default/* will match any channel in the default namespace. When multiple handlers match the same event, the library will call the most specific handler and ignore the less specific ones. For example, if a handler is registered for /default/channel1 and another one for /default/\\*, Powertools will call the first handler for events that match /default/channel1 and ignore the second one. This provides you control over how events are handled and to avoid unnecessary processing. If an event that does not match any handler, by default Powertools will return the events as is and log a warning. This means that the events will be passed through without any modifications. This approach is helpful for gradually adopting the library, allowing you to handle specific events with custom logic while others are processed by the default behavior.\nSubscription Handling Powertools also provides a simple way to handle subscription events. It will automatically parse the incoming event and call the appropriate handler based on the event type. By default, AppSync allows the subscription unless your Lambda handler either throws an error or explicitly rejects the request. When a subscription is rejected, AppSync will return a 4xx response to the client and prevent the subscription from being established.\nimport { AppSyncEventsResolver } from \u0026#39;@aws-lambda-powertools/event-handler/appsync-events\u0026#39;; import { Metrics, MetricUnit } from \u0026#39;@aws-lambda-powertools/metrics\u0026#39;; import type { Context } from \u0026#39;aws-lambda\u0026#39;; const metrics = new Metrics({ namespace: \u0026#39;serverlessAirline\u0026#39;, serviceName: \u0026#39;chat\u0026#39;, singleMetric: true, }); const app = new AppSyncEventsResolver(); app.onSubscribe(\u0026#39;/default/foo\u0026#39;, (event) =\u0026gt; { metrics.addDimension(\u0026#39;channel\u0026#39;, event.info.channel.path); metrics.addMetric(\u0026#39;connections\u0026#39;, MetricUnit.Count, 1); }); export const handler = async (event: unknown, context: Context) =\u0026gt; app.resolve(event, context); The library calls the appropriate handler and passes the event object as the first argument when a subscription event arrives. You can take any necessary actions based on the subscription event, such as running access control checks:\napp.onSubscribe(\u0026#39;/private/\\*\u0026#39;, async (info) =\u0026gt; { const userGroups = info.identity?.groups \u0026amp;\u0026amp; Array.isArray(info.identity?.groups) ? info.identity?.groups : []; const channelGroup = \u0026#39;premium-users\u0026#39;; if (!userGroups.includes(channelGroup)) { throw new UnauthorizedException( `Subscription requires ${channelGroup} group membership` ); } }) Subscription events follow the same matching rules and provide the same access to the full event and context. You can register catch-all handlers for any namespace or channel by using the wildcard * character, and also access the full event and context objects in your handlers.\nAccess full event and context While the resolver simplifies event handling, you still have full access to the event and context objects when needed. This is helpful in scenarios where you need additional information, such as request headers or the remaining execution time from the Lambda context, to implement custom logic.\nThe resolver passes the full event and context to each handler as the second and third arguments. This lets you access all relevant information without changing your existing code\nimport { AppSyncEventsResolver } from \u0026#39;@aws-lambda-powertools/event-handler/appsync-events\u0026#39;; import { Logger } from \u0026#39;@aws-lambda-powertools/logger\u0026#39;; const logger = new Logger({ logLeveL: \u0026#39;INFO\u0026#39;, serviceName: \u0026#39;serverlessAirline\u0026#39; }); const app = new AppSyncEventsResolver({ logger}); app.onPublish(\u0026#39;/orders/process\u0026#39;, async (payload, event, context) =\u0026gt; { // Access request headers const { headers } = event.request; // Access Lambda context const { getRemainingTimeInMillis } = context; logger.info(\u0026#39;Processing event details\u0026#39;, { headers, remainingTime: getRemainingTimeInMillis() }); return payload; }); export const handler = async (event, context) =\u0026gt; app.resolve(event, context);: Error handling The AppSyncEventsResolver offers built-in error handling that prevents Lambda function failures while ensuring errors are properly communicated to AppSync, which then propagates them to the clients. When an error occurs in your handler, instead of failing the entire Lambda invocation, the resolver captures the error and includes it in the response payload for the specific event that failed.\nThis approach ensures the Lambda function continues execution while providing properly formatted error messages to AppSync. When processing multiple events, if one event fails, the others continue processing normally. This is particularly useful in parallel processing scenarios where you want to ensure that an error in one event doesn’t affect the processing of other events.\nimport { AppSyncEventsResolver } from \u0026#39;@aws-lambda-powertools/event-handler/appsync-events\u0026#39;; const app = new AppSyncEventsResolver(); app.onPublish(\u0026#39;/messages\u0026#39;, async (payload) =\u0026gt; { // If message contains \u0026#34;error\u0026#34;, throw an exception if (payload.message === \u0026#34;error\u0026#34;) { throw new Error(\u0026#34;Invalid message\u0026#34;); } return payload; }); export const handler = async (event, context) =\u0026gt; app.resolve(event, context); // When processing this event: // { // \u0026#34;id\u0026#34;: \u0026#34;123\u0026#34;, // \u0026#34;payload\u0026#34;: { // \u0026#34;message\u0026#34;: \u0026#34;error\u0026#34; // } // } // The resolver will return: // { // \u0026#34;id\u0026#34;: \u0026#34;123\u0026#34;, // \u0026#34;error\u0026#34;: \u0026#34;Error - Invalid message\u0026#34; // } Advanced Patterns and Best Practices The AppSyncEventsResolver has additional advanced features that help you build robust and maintainable real-time applications. Let’s explore these capabilities and how to use them effectively.\nOn publish processing By default, we call your route handler once per message. This allows you to focus on your business logic and avoid writing boilerplate code while Powertools handles message iteration and converts the event and response format. You only need to return the value you want to use as payload, or throw an error for that message. The library will then correlate the payload with the correct event id.\nimport { AppSyncEventsResolver } from \u0026#39;@aws-lambda-powertools/event-handler/appsync-events\u0026#39;; import { Metrics, MetricUnit } from \u0026#39;@aws-lambda-powertools/metrics\u0026#39;; type SensorReading = { deviceId: string; temperature: number; humidity: number; timestamp: string; } const app = new AppSyncEventsResolver(); const metrics = new Metrics({ namespace: \u0026#39;SensorReadings\u0026#39; }); app.onPublish(\u0026#39;/sensors/readings\u0026#39;, async (payload: SensorReading) =\u0026gt; { // Process each sensor reading independently if (payload.temperature \u0026gt; 100) { metrics.addDimension(\u0026#39;alertType\u0026#39;, \u0026#39;highTemperature\u0026#39;); metrics.addMetric(\u0026#39;HighTemperature\u0026#39;, MetricUnit.Count, 1); throw new Error(\u0026#39;Temperature reading too high\u0026#39;); } // Enrich the payload with processing timestamp return { ...payload, processed: true, processedAt: new Date().toISOString() }; }); export const handler = async (event, context) =\u0026gt; app.resolve(event, context); This pattern simplifies development by letting you write only the logic for a single event, Powertools handles the rest automatically.\nAggregate Processing The aggregate mode lets you to process multiple events as a single batch, rather than handling them individually. This is particularly useful when you want to optimize resource usage, such as sending multiple queries to a database in a single operation, or to analyze multiple events together before processing them. While both modes give you full control over event processing, aggregate mode provides access to the entire list of events at once.\nTo achieve this, you can set the aggregate option to true. When using this mode, the resolver sends the entire list of events to your handler in a single call, letting you process them as a batch.\nimport { AppSyncEventsResolver } from \u0026#39;@aws-lambda-powertools/event-handler/appsync-events\u0026#39;; const app = new AppSyncEventsResolver(); app.onPublish(\u0026#39;/default/*\u0026#39;, async (events) =\u0026gt; { const results = []; for (const event of events) { try { results.push(await handleDefaultNamespaceCatchAll(event)); } catch (error) { results.push({ error: { errorType: \u0026#39;Error\u0026#39;, message: error.message, }, id: event.id, }); } } return results; }, { aggregate: true, }); export const handler = async (event, context) =\u0026gt; app.resolve(event, context); Note that the aggregate option is only available for publish events, and that when using this option, you are responsible for handling the events and returning the appropriate response. Powertools will still take care of routing the events to the correct handler, but you have full control over how the events are processed.\nEvent Filtering To filter out an event, throw an error in the channel handler. If a handler throws an error for a specific event, the library catches it and adds an error object to the response list at the same index. This signals that the corresponding message should be dropped. This allows you to either silently filter events or provide meaningful error feedback to your subscribers.\nimport { AppSyncEventsResolver } from \u0026#39;@aws-lambda-powertools/event-handler/appsync-events\u0026#39;; app.onPublish(\u0026#39;/moderation/\\*\u0026#39;, async (payload) =\u0026gt; { // Filter out inappropriate content if (await containsInappropriateContent(payload)) { throw new CustomError(\u0026#39;Content violates guidelines\u0026#39;); } // Process valid content return await processContent(payload); }); export const handler = async (event, context) =\u0026gt; app.resolve(event, context); Conclusion The AppSyncEventsResolver in Powertools for AWS enhances your development experience with AppSync Events by providing a simple and consistent interface for processing real-time events. By reducing boilerplate code and offering built-in support for common patterns, you can focus on your business logic rather than infrastructure code.\nTo learn more:\nExplore the Powertools for AWS documentation for detailed information. Check out the AppSync Events documentation to learn more about the service. Visit our GitHub repository to contribute or report issues. We’re excited to see what you build with these new capabilities. Share your feedback and let us know how you’re using AppSyncEventsResolver in your applications!\nTAGS: AppSync, AWS Lambda\n"},{"uri":"https://sharonng1029.github.io/fcj-fall2025-internship-report/","title":"Internship Report","tags":[],"description":"","content":"Internship Report Student Information: Full Name: Nguyen Nhat Kim Ngan\nPhone Number: +84 333 982 942\nEmail: ngannnkse182088@fpt.edu.vn\nUniversity: Ho Chi Minh FPT University\nMajor: Software Engineering\nClass: OJT202\nInternship Company: Amazon Web Services Vietnam Co., Ltd.\nInternship Position: FCJ Cloud Intern\nInternship Duration: From 12/08/2025 to 12/11/2025\nReport Content Worklog Proposal Translated Blogs Events Participated Workshop Self-evaluation Sharing and Feedback "},{"uri":"https://sharonng1029.github.io/fcj-fall2025-internship-report/1-worklog/1.1-week1/","title":"Week 1 Worklog","tags":[],"description":"","content":"Week 1 Objectives: Onboard and set up the working environment. Gain foundational knowledge of Cloud Computing and AWS Global Infrastructure. Get familiar with IAM and basic account security. Tasks to be carried out this week: Day Tasks Start Completed References 2 - Get acquainted with FCJ members.\n- Read and take note of training rules and guidelines.\n- Learn about AWS and its main service categories:\n+ Compute (EC2, Lambda)\n+ Storage (S3, EBS)\n+ Networking (VPC)\n+ Database (RDS, DynamoDB) 08/09/2025 08/09/2025 AWS Cloud Concepts 3 - Create an AWS Free Tier account.\n- Configure MFA for Root User.\n- Set up Billing Alarm (threshold $5). 09/09/2025 10/09/2025 Create AWS Account 4 - Explore AWS Console \u0026amp; AWS CLI.\n- Practice:\n+ Install AWS CLI v2\n+ Configure aws configure\n+ Try basic CLI commands 10/09/2025 11/09/2025 Install AWS CLI 5 - Learn about Secure Architectures (Part 1 - IAM):\n+ IAM User, Group, Role\n+ Policy \u0026amp; Permissions\n+ Principle of Least Privilege\n- Practice: Create Admin User and assign permissions. 11/09/2025 12/09/2025 IAM Best Practices 6 - Learn about AWS Global Infrastructure:\n+ Region\n+ Availability Zone (AZ)\n+ Edge Location 12/09/2025 13/09/2025 Global Infrastructure Week 1 Achievements: 1. AWS Foundation Knowledge:\nUnderstood Cloud Computing concepts and the IaaS, PaaS, SaaS models. Learned core service groups: Compute, Storage, Networking, Database. Understood global infrastructure structure (Region, AZ) to design resilient systems. 2. Account Management \u0026amp; Security (IAM):\nSuccessfully created and configured an AWS Free Tier account. Enabled MFA to protect the Root account. Set up Billing Alarm to monitor budget usage. Understood and applied key IAM concepts: User, Group, Policy. 3. Tooling Skills (CLI):\nInstalled and configured AWS CLI on the local machine. Understood configuration details: Access Key, Secret Key, Default Region. Executed basic commands: aws s3 ls, aws ec2 describe-instances, aws iam list-users. "},{"uri":"https://sharonng1029.github.io/fcj-fall2025-internship-report/1-worklog/","title":"Worklog","tags":[],"description":"","content":"On this page, I document my entire internship journey at FCJ (First Cloud Journey) – a 14-week training program (from September 8, 2025 to December 14, 2025). This was my first time systematically learning and practicing AWS services from fundamental to advanced levels, while also completing a serverless group project called Serverless Student Management System.\nDuring the 3.5-month internship, I went through the following phases:\nWeeks 1–4: Building AWS fundamentals (IAM, S3, EC2, VPC, Database…) Weeks 5–6: Learning Decoupling, advanced Security, and project ideation Weeks 7–8: Selecting the project topic, designing the architecture, and preparing for the midterm exam (4 pillars: Security, Resilience, Performance, Cost Optimization) Weeks 9–10: Business analysis, Proposal writing, UI/UX design Weeks 11–13: Frontend development (React + TypeScript), Cognito integration, API Gateway, CloudFront + WAF, Route53 Below is a weekly summary of the work:\nWeek 1: Onboarding, IAM, AWS Global Infrastructure\nWeek 2: Learning Amazon S3, Static Website Hosting, and getting familiar with Draw.io\nWeek 3: Learning EC2, EBS, Security Groups, Load Balancing, Auto Scaling\nWeek 4: Learning VPC, Subnets, NAT Gateway, Resilient Architecture\nWeek 5: Learning RDS, DynamoDB, Well-Architected Framework\nWeek 6: Learning SQS, SNS, KMS, Secrets Manager, choosing Serverless\nWeek 7: Selecting the project topic, drawing the Architecture, starting midterm review\nWeek 8: Midterm review and completing the exam\nWeek 9: Use Case analysis, Flowchart, ERD, writing the Proposal, cost estimation\nWeek 10: Submitting the Proposal, designing UI/UX Wireframes, AI/ML Event\nWeek 11: DevOps Event, designing DynamoDB Schema, setting up React + TypeScript + Vite, integrating Cognito\nWeek 12: Completing the Admin Dashboard UI, Security Event\nWeek 13: Integrating API Gateway, deploying CloudFront + WAF, Route53 (Custom Domain)\n"},{"uri":"https://sharonng1029.github.io/fcj-fall2025-internship-report/4-eventparticipated/4.1-event1/","title":"Event 1","tags":[],"description":"","content":"Summary Report: Kick-off AWS First Cloud Journey Workforce – OJT FALL 2025 Event Objectives Officially launch the AWS First Cloud Journey (FCJ) program for the Fall 2025 cohort. Provide a comprehensive roadmap of the program, setting expectations for real-world projects and On-the-Job Training (OJT). Outline career orientations in high-demand fields: Cloud Computing, AI/GenAI, and DevOps. Inspire interns by connecting them with mentors, successful alumni, and the broader AWS Vietnam community. Time \u0026amp; Venue Time: 08:30 – 12:00, Saturday, September 06, 2025\nVenue: 26th Floor, Bitexco Financial Tower, 2 Hai Trieu Street, Ben Nghe Ward, District 1, Ho Chi Minh City\nSpeakers Program Leaders \u0026amp; Educators\nMr. Nguyen Tran Phuoc Bao – Head of Corporate Relations, FPT University Mr. Nguyen Gia Hung – Head of Solutions Architect, AWS Vietnam Industry Experts \u0026amp; Alumni Panel\nDo Huy Thang – DevOps Lead, VNG Danh Hoang Hieu Nghi – GenAI Engineer, Renova Bui Ho Linh Nhi – AI Engineer, SoftwareOne Pham Nguyen Hai Anh – Cloud Engineer, G-Asia Pacific Nguyen Dong Thanh Hiep – Principal Cloud Engineer, G-Asia Pacific Key Highlights 1. The FCJ Vision \u0026amp; Impact Legacy: Since 2021, FCJ has trained over 2,000 students, creating a pipeline of 150+ alumni currently working at top tech companies. Mission: To build a high-quality generation of AWS Builders for Vietnam, capable of competing globally. Ecosystem: The program is deeply connected to the AWS Study Group (47,000+ members), providing a massive support network for new joiners. 2. Industry Insights \u0026amp; Career Accelerators Rapid Growth: The sharing session highlighted how Alumni transitioned from Interns to roles like Principal Cloud Engineer or GenAI Engineer in just 1–3 years. Key Trends: The shift from traditional SysAdmin to modern roles requires a mix of Cloud Native, Infrastructure as Code (IaC), and Generative AI skills. Recruitment Reality: Employers are looking for \u0026ldquo;Builders\u0026rdquo; who can demonstrate practical project experience, not just certificate holders. 3. The \u0026ldquo;Builder\u0026rdquo; Mentality Core Advice: \u0026ldquo;Learn fast – build real projects – ask early – share more.\u0026rdquo; Proactivity: Success in the OJT program relies 80% on the intern\u0026rsquo;s proactivity in seeking mentorship and solving problems independently before asking. Key Takeaways Mindset \u0026amp; Culture Contribution Culture: Knowledge grows when shared. Active participation in the community is the fastest way to learn. Fail Fast, Learn Faster: Don\u0026rsquo;t be afraid to break things in the lab environment. It\u0026rsquo;s better to fail during OJT than in a production environment. Career Strategy T-Shaped Skills: Build a broad foundation in AWS services (Compute, Network, Storage) but develop deep expertise in one domain (e.g., Serverless or GenAI). Network is Net Worth: The relationships built with mentors and peers in this program are future professional connections. Skill Orientation Focus Areas: The current market demands proficiency in Serverless (Lambda, API Gateway), Terraform/CDK, and CI/CD pipelines. Soft Skills: Communication and documentation are just as critical as coding. Applying to Work Define Roadmap: Set a clear goal for the 4-month internship: Achieve the AWS Solutions Architect Associate certification and complete one end-to-end capstone project. Portfolio Building: Commit to documenting every weekly task and project milestone on GitHub and personal blogs (like this Hugo site). Mentorship Engagement: Schedule bi-weekly checkpoints with the assigned mentor to review code quality and discuss architectural decisions for the Student Management System project. Event Experience The Kick-off event was more than just an orientation; it was a motivational booster.\nInspiration: Hearing specific stories from alumni like Nguyen Dong Thanh Hiep (Principal Cloud Engineer) proved that a steep career trajectory is possible with the right focus. Atmosphere: The energy at the AWS Office was palpable. Being surrounded by 300+ like-minded peers created a sense of belonging to a \u0026ldquo;technical elite\u0026rdquo; squad. Direct Connection: I had the opportunity to listen directly to Mr. Nguyễn Gia Hưng, and his vision for Vietnam’s technology workforce truly motivated me to strive harder. Event Photos "},{"uri":"https://sharonng1029.github.io/fcj-fall2025-internship-report/5-workshop/5.4-frontend/5.4.2-cloudfrontwaf/","title":"Amazon CloudFornt &amp; WAF","tags":[],"description":"","content":"CLOUDFRONT + WAF 1. Create WAF Web ACL Go to AWS Console → WAF \u0026amp; Shield → Create web ACL Configuration: Name: student-management-waf Resource type: CloudFront distributions Region: Global (CloudFront) Add rules: AWS Managed Rules:\nAWSManagedRulesCommonRuleSet (Core rule set) AWSManagedRulesKnownBadInputsRuleSet AWSManagedRulesSQLiRuleSet (SQL injection) Rate limiting:\nName: RateLimitRule Rate limit: 2000 requests per 5 minutes per IP Rate limiting: Name: RateLimitRule Rate limit: 2000 requests per 5 minutes per IP 2. Create CloudFront Distribution Go to AWS Console → CloudFront → Create distribution\nOrigin Settings:\nOrigin domain: Amplify app URL (xxx.amplifyapp.com) Protocol: HTTPS only Default Cache Behavior:\nViewer protocol policy: Redirect HTTP to HTTPS Allowed HTTP methods: GET, HEAD, OPTIONS, PUT, POST, PATCH, DELETE Cache policy: CachingOptimized Origin request policy: AllViewer Settings:\nPrice class: Use all edge locations WAF web ACL: Choose the created ACL SSL certificate: Default CloudFront certificate (hoặc custom) Add Origin for API Gateway:\nAdd origin: API Gateway URL Create behavior: /api/* → API Gateway origin "},{"uri":"https://sharonng1029.github.io/fcj-fall2025-internship-report/5-workshop/5.3-backend/5.3.2-amazoncognito/","title":"Amazon Cognito","tags":[],"description":"","content":"Amazon Cognito 1. Create User Pool Go to AWS Console → Cognito → Create user pool Configuration: Sign-in: Email Password policy: Minimum 8 characters MFA: Optional Email: Send email with Cognito Create App Clients: App client name: student-management-app Generate client secret: No Auth flows: ALLOW_USER_SRP_AUTH, ALLOW_REFRESH_TOKEN_AUTH 2. Save information VITE_COGNITO_USER_POOL_ID=ap-southeast-1_XXXXXXXX VITE_COGNITO_CLIENT_ID=xxxxxxxxxxxxxxxxxxxxxxxxxxx VITE_COGNITO_REGION=ap-southeast-1 "},{"uri":"https://sharonng1029.github.io/fcj-fall2025-internship-report/5-workshop/5.2-prerequiste/","title":"Prerequiste","tags":[],"description":"","content":"To successfully deploy the Serverless Student Management System Workshop, it is necessary to fully prepare the technical environment, AWS account and platform services according to the serverless – event-driven architecture.\nThis page guides the essential steps before starting to develop the backend, frontend and event components.\nPrepare AWS account Create and configure AWS account Create a personal AWS account or use AWS Educate/AWS Academy.\nActivate AWS Free Tier to optimize costs during the workshop period.\nEnable MFA to secure the root account.\nCreate IAM User for team members and assign roles according to the Least Privilege principle.\nFigure 1: Sample IAM users.\rSet up IAM Permissions To fully deploy the project\u0026rsquo;s serverless system, the IAM User needs permission to operate with:\nAWS Lambda DynamoDB API Gateway Cognito S3 CloudWatch Amplify IAM (limited to PassRole and Lambda role creation operations) An example of a broad permission policy for workshop purposes:\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;ServerlessStudentManagementWorkshopAccess\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;cloudformation:*\u0026#34;, \u0026#34;cloudwatch:*\u0026#34;, \u0026#34;logs:*\u0026#34;, \u0026#34;s3:*\u0026#34;, \u0026#34;lambda:*\u0026#34;, \u0026#34;dynamodb:*\u0026#34;, \u0026#34;apigateway:*\u0026#34;, \u0026#34;cognito-idp:*\u0026#34;, \u0026#34;cognito-identity:*\u0026#34;, \u0026#34;route53:*\u0026#34;, \u0026#34;acm:*\u0026#34;, \u0026#34;waf:*\u0026#34;, \u0026#34;cloudfront:*\u0026#34;, \u0026#34;amplify:*\u0026#34;, \u0026#34;codebuild:*\u0026#34;, \u0026#34;codedeploy:*\u0026#34;, \u0026#34;codepipeline:*\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } "},{"uri":"https://sharonng1029.github.io/fcj-fall2025-internship-report/2-proposal/","title":"Proposal","tags":[],"description":"","content":"Serverless Student Management System This is the DOCX version of the proposal. Download the Proposal to view more details.\n1. Executive Summary Serverless Student Management Platform is a cloud-based student management platform designed for educational institutions and small businesses to enhance the ability to manage, analyze, and interact with student data. The platform supports up to 50-100 students initially, with the ability to flexibly scale up to 500–1000 students without major infrastructure changes, using AWS Serverless services such as Lambda, DynamoDB, API Gateway.\n2. Problem Statement Current Problem\nCurrent student management systems require manual data entry, which is difficult to manage when there are many classes. There is no centralized system for real-time data or analytics, and third-party platforms are often expensive and too complex.\nSolution\nThe platform uses Amazon API Gateway to receive REST requests, AWS Lambda to handle business logic, Amazon DynamoDB to store student data and scores. AWS Amplify with React/TypeScript provides the web interface, and Amazon Cognito ensures secure access. Similar to traditional LMS systems but at a lower cost, users can register new students and manage information, but the platform operates at a smaller scale and serves learning purposes.\nBenefits and ROI\nThe solution creates a basic foundation for IT students to develop serverless AWS skills, while providing effective management tools for teachers to support teaching and assessment. The platform reduces manual reporting for each class through a centralized system, simplifies management and maintenance, and improves data reliability. The estimated monthly cost is $7-20 USD according to the detailed budget estimate, totaling $40-60 USD for 3 months.\n3. Solution Architecture The system is designed according to the AWS Well-Architected Framework architecture with interconnected layers, ensuring data management, authentication, and monitoring capabilities. The serverless architecture helps optimize costs and ensure automatic scalability.\nAWS Core Services Used Services Key Features Key Benefits Amazon Route 53 Manage DNS and route traffic to CloudFront Set up custom domains, health checks, geo-routing, SSL integration to ensure secure and fast access. Amazon CloudFront CDN delivery for static content and frontend resources Global latency reduction, caching at edge locations, HTTPS support, WAF integration for protection and OAC for S3. AWS WAF Firewall to protect web applications from attacks Block malicious requests, rate limiting, IP filtering, seamless integration with CloudFront to secure traffic. AWS Amplify Frontend hosting and deployment with CI/CD Build and deploy web applications quickly, integrate with Cognito/AppSync for user-friendly interface and real-time chat. Amazon API Gateway Handle and route API requests from frontend to backend Support REST/HTTP APIs, throttling, caching, and authorizer for increased performance and security. Amazon Cognito Manage user authentication and authorization Support MFA, JWT tokens, groups for permissions (teacher/admin vs. student), easy integration with AppSync/API Gateway. AWS Lambda Execute backend logic and event handling Serverless, auto-scaling, pay-per-use, CRUD processing. Amazon DynamoDB NoSQL data storage for student information, chat, and assignments Fast query, auto-scaling, Global Secondary Indexes (GSI) support for complex searches and low cost. Amazon CloudWatch Monitor logs, metrics, and system alarms Real-time monitoring, set alarms to detect problems early, integrate with Lambda/DynamoDB for optimization. Amazon S3 Store artifacts and builds from CI/CD Cheap, highly sustainable static file hosting, integrated with CodePipeline to store deployed artifacts. GitLab Manage source code and trigger CI/CD pipeline Version control (GitLab.com or self-hosted), merge requests, issue tracking, webhooks integrated with CodePipeline to automate deployment. AWS CodePipeline Orchestrate CI/CD pipeline from source to deploy Automate the entire process from GitLab to production, integrated with CodeBuild/CodeDeploy, support approvals and notifications. AWS CodeBuild Build and test code from GitLab repository Automatically compile, package artifacts, run unit tests in pipeline, support multi-environment builds. AWS CodeDeploy Deploy applications to AWS services Support blue/green deployment, automatic rollback, zero-downtime deployments for Lambda/Amplify. Component Design Layer Main Components Functionality Edge Layer Route53, CloudFront, WAF DNS, CDN, security layer Frontend Layer Amplify, Cognito Web interface, realtime chat, authentication Backend Layer API Gateway, Lambda, DynamoDB Logic processing, CRUD, data storage Monitoring Layer CloudWatch Logs, metrics, alerts CI/CD Layer GitLab, CodePipeline, CodeBuild, CodeDeploy, S3 Build \u0026amp; deploy automation Main Flow Annotation Flow Description (1) User accesses via Route53 → CloudFront → Amplify (frontend). (2) Amplify communicates with API Gateway to send/receive data. (3.1) API Gateway → Lambda to handle logic (CRUD, etc.). (3.2) Cognito authenticates and returns tokens. (4) Dev pushes code to GitLab → CodePipeline pull → CodeBuild/CodeDeploy → Amplify/Lambda. (5) CloudWatch collects logs and metrics. 4. Technical Implementation Implementation Phases The project was implemented in 5 weeks with 5 main phases:\nWeek 1 - Foundation Setup Days 1-2: Set up AWS account, configure IAM roles/policies, set up billing alerts Days 3-4: Create DynamoDB tables (Students, Courses, Grades, Assignments) with GSI, configure Cognito User Pools with groups (Admin/Teacher/Student) Days 5-7: Initialize IaC templates (AWS CDK/CloudFormation), research serverless patterns, design detailed architecture with sequence diagrams, setup Git repo structure for parallel development Week 2 - Backend \u0026amp; Frontend Parallel (Parallel Development Phase 1) Backend Team (Day 1-7): Build 50+ Lambda functions for: Students (CRUD, search, bulk import/export), Courses (CRUD, enrollment), Grades (CRUD, analytics, statistics), Assignments (CRUD, submissions), Auth (login, registration, refresh token) Set up API Gateway with 50+ REST endpoints: /students/* (10 endpoints), /courses/* (8 endpoints), /grades/* (12 endpoints), /assignments/* (8 endpoints), /attendance/* (6 endpoints) Unit testing with 80%+ coverage Frontend Team (July 1): Deploy Amplify hosting with React/TypeScript, setup routing (React Router) Build UI components: Layout (Header, Sidebar, Footer), Authentication (Login, Register), Dashboard (Overview, Stats cards) Setup API client (Axios/Fetch), state management (Redux/Zustand), form validation (React Hook Form) Week 3 - Backend \u0026amp; Frontend Parallel (Parallel Development Phase 2) Backend Team (Day 1-7): Integrate Lambda handlers for automated workflows Integration testing with Postman/SWAGGER Frontend Team (July 1): Build 15+ pages: Student Management (List, Create, Edit, Detail, Import), Course Management (List, Create, Edit, Enrollment), Grade Management (List, Input, Analytics), Assignment (List, Submit, Review) Integration (Days 6-7): Connect CloudFront CDN with Route53, configure WAF rules (rate limiting, geo-blocking), SSL/TLS certificates End-to-end testing between Frontend and Backend Week 4 - CI/CD with CodeBuild, CodeDeploy, CodePipeline Day 1-2: Learn and configure AWS CodeBuild for frontend and backend (buildspec, build environment, save artifacts to S3) Day 3-4: Set up AWS CodePipeline to automate the build and deploy process from GitLab to AWS environment (connect stages: source, build, deploy) Day 5-6: Configure AWS CodeDeploy to deploy backend (Lambda or EC2) and frontend (Amplify or S3), test the automated deployment process Day 7: Test the entire pipeline, ensure the build, automated deployment works stably, record results and optimize the pipeline Week 5 - Testing \u0026amp; Demo (Testing \u0026amp; Launch) Day 1-2: End-to-end testing (user flows, edge cases), load testing with 100+ concurrent users Day 3-4: Performance optimization (Lambda memory tuning, DynamoDB capacity adjustment, CloudFront caching) Day 5-6: Complete documentation (architecture diagrams, API docs, deployment guide, user manual) Day 7: Demo preparation, presentation slides, video recording Technical Requirements Student Management System: Full web dashboard with 5 main modules (Students, Courses, Grades, Assignments, Attendance). Frontend React/TypeScript running on Amplify Hosting with 15+ pages and 50+ components. Cognito authenticates and authorizes all users, including 5-10 admins/teachers (with high permissions like CRUD data) and students (with limited permissions like viewing scores, classes).\nComprehensive API architecture: 50+ REST API endpoints via API Gateway (CRUD operations, search, bulk actions). Backend built in parallel with Frontend to optimize development time.\nSmart Analytics Platform: Practical knowledge of AWS Amplify (hosting React), Lambda (50+ business processing functions), DynamoDB (5 tables with GSI). Use AWS CDK/SDK for IaC programming and automation. Parallel development methodology with Git branching strategy for Backend/Frontend teams.\n5. Roadmap \u0026amp; Milestones To fit the internship time, the project is implemented in 5 weeks with 5 main phases:\nPhase Time Main Objective Deliverables Success Criteria 1: Setting up the foundation Week 1 Setting up the AWS environment • AWS account with IAM setup\n• 7 DynamoDB tables with GSI\n• Cognito User Pool\n• IaC templates (CDK/CloudFormation)\n• Git repo structure • Infrastructure as Code complete\n• Security baseline up to standard\n• Parallel dev environment ready 2: Backend \u0026amp; Frontend Parallel (Phase 1) Week 2 Build core Backend + Frontend foundation • 50+ Lambda functions\n• API Gateway with 50+ REST endpoints\n• React/TypeScript app foundation\n• 10+ UI components\n• Unit tests (\u0026gt;80% coverage) • 50+ active API endpoints\n• API response time \u0026lt;500ms\n• Frontend routing setup\n• All backend tests passed 3: Backend \u0026amp; Frontend Parallel (Phase 2) Week 3 Integrating Lambda workflows \u0026amp; integration testing • Integrating Lambda handlers for automated workflows\n• Integration testing with Postman/SWAGGER\n• 15+ complete pages\n• CloudFront + Route53 + WAF\n• Responsive design • Automated workflows work well\n• Integration tested with Postman/SWAGGER\n• All pages integrated with backend\n• SSL/HTTPS enabled\n• Mobile responsive 4: CI/CD with CodeBuild, CodeDeploy, CodePipeline Week 4 Set up and test automated CI/CD process • Configure CodeBuild for frontend/backend\n• Set up CodePipeline connecting GitLab, CodeBuild, CodeDeploy\n• Test automated deployment for backend/frontend • Build and deploy automation work well\n• Artifacts stored correctly\n• Pipeline optimized 5: Test \u0026amp; Demo Week 5 Test and finalize • Load test reports (50+ users)\n• Performance optimization\n• Complete documentation\n• Demo video + slides • System uptime ≥99%\n• All features stable\n• Documentation complete\n• Demo ready 6. Budget Estimate Download budget estimate file for detailed cost information.\nInfrastructure Costs AWS Services:\nServices Usage Description Estimated Cost / Month (USD) Notes Amazon API Gateway Handles ~100k-500k API calls/month $3.8 HTTP APIs, REST APIs, first 1M calls free AWS Lambda ~200k-500k requests, 100k-200k GB-sec $0.5 Requests, GB-sec, 1M requests + 400k GB-sec free Amazon DynamoDB ~5-10 GB storage, 250k-500k reads/writes $1 Reads, Writes, Storage, 25 GB + 25 RCU/WCU free Amazon Cognito ~100-200 monthly active users $0 First 10k users free Amazon S3 ~5 GB storage, low requirements $0.13 Storage, requests, free credits available Amazon CloudWatch ~5 GB logs, 10 metrics/alarms $4 Logs, metrics, alarms, 5 GB free AWS Amplify Dashboard hosting, few builds/month $1 Build minutes, storage, free credits available Amazon Route 53 DNS queries, storage zones $1 Storage zone, DNS queries AWS WAF Web ACL Assessment, Rules $7 Web ACL, rules, rule management costs extra AWS CodeBuild ~10 builds/month, 100 minutes $0.9 $0.005/min build, 100 minutes/month free AWS CodeDeploy Application Deployment $0.8 EC2/on-premises, serverless free Amazon CloudFront Static Content Delivery CDN $1 First 1 TB/month free, $0.085/GB thereafter AWS CodePipeline CI/CD automation (GitLab → CodeBuild → CodeDeploy) $1 $1/month for each active pipeline Estimated total Total cost / month (estimated) 3-month total (estimated) With AWS Free Tier Notes ~$7 – $20 / month ~$40 – $60 / 3 months ~$15 – $30 / 3 months Depends on actual usage. Take advantage of Free Tier (first year) + AWS Educate credits to reduce costs by 50%. Note All core services are included in the first year free plan. Additional discounts may apply if using AWS Educate / Student Credits. 7. Risk Assessment Based on the NIST Risk Management Framework, the project team identified key risks and mitigation measures.\nRisk Code Description Level Mitigation R1 – Data Leakage Data exposure due to incorrect configuration High Apply Cognito auth, IAM least privilege, DynamoDB encryption R2 – API Overload Too many requests causing slowness Medium Throttling API Gateway/AppSync, CloudWatch alarms R3 – Lambda Cold Start Delay when invoking Medium Optimize code, Provisioned Concurrency if needed R4 – Cost Overrun Unusual usage increase (high emails) Medium AWS Budgets alerts, monitor Cost Explorer R5 – Service Downtime AWS Outage Low Multi-AZ config, backups DynamoDB Contingency Plan (Summary):\nRecovery: Use CloudFormation to quickly recreate infrastructure in the event of a failure or deployment error.\nMonitoring \u0026amp; Alerting: Set up CloudWatch alarms to detect performance, security, and cost issues early, send email notifications to the operations team.\nContinuous Improvement: Periodically evaluate CI/CD processes, automate testing, optimize pipelines, and update documentation to ensure the system is always stable and easy to maintain.\n8. Expected Results Technical Results:\nComplete a serverless student management system with an automated CI/CD process, ensuring fast and stable build, test, and deployment.\nAPI fully supports student management functions, integrates Lambda workflows, integration testing with Postman/SWAGGER.\nModern frontend with React/TypeScript, 15+ pages, 50+ UI components, realtime connection with backend.\nIntegrates key AWS services: API Gateway, Lambda, DynamoDB, Cognito, S3, Amplify, CloudWatch, Route53, CloudFront, WAF, CodePipeline, CodeBuild, CodeDeploy.\nPerformance: API response \u0026lt;500ms, uptime ≥99%, CI/CD process optimizes cost and deployment time.\nActual cost: $7-20/month, total ~$21-60 for 3 months (can be reduced to $15-30 with AWS Free Tier and Educate credits).\nLong-term value:\nEasily expandable to mobile apps or advanced AI/analytics integration. A practice and training platform for serverless, CI/CD, and DevOps for students and small businesses. "},{"uri":"https://sharonng1029.github.io/fcj-fall2025-internship-report/4-eventparticipated/4.2-event2/","title":"Event 2","tags":[],"description":"","content":"Summary Report: Vietnam Cloud Day 2025 - Ho Chi Minh City Connect Edition for Builders (Track: Migration \u0026 Modernization) Event Objectives Update on strategic Cloud, GenAI, and Modernization trends for 2025–2026 in Vietnam. Gain insights directly from senior leadership of AWS APJ and major enterprises (Techcombank, OCB, TymeX, U2U Network). Master practical best practices for migration, modernization, and applying Generative AI in the enterprise SDLC. Understand the \u0026ldquo;Security-by-design\u0026rdquo; approach in large-scale systems. Time \u0026amp; Venue Time: 09:00 – 17:00, Thursday, September 18, 2025\nVenue: 36th Floor, Bitexco Financial Tower, 2 Hai Trieu Street, Ben Nghe Ward, District 1, Ho Chi Minh City\nSpeakers Live Telecast\nEric Yeo – Country General Manager Vietnam, Cambodia, Laos \u0026amp; Myanmar, AWS Jaime Valles – Vice President \u0026amp; General Manager Asia Pacific and Japan, AWS Dr. Jens Lottner – CEO, Techcombank Ms. Trang Phung – CEO \u0026amp; Co-Founder, U2U Network Jeff Johnson – Managing Director ASEAN, AWS Vu Van – Co-founder \u0026amp; CEO, ELSA Corp Nguyen Hoa Binh – Chairman, Nexttech Group Dieter Botha – CEO, TymeX Track Migration \u0026amp; Modernization\nHung Nguyen Gia – Head of Solutions Architect, AWS Vietnam Son Do – Technical Account Manager, AWS Nguyen Van Hai – Director of Software Engineering, Techcombank Phuc Nguyen – Solutions Architect, AWS Alex Tran – AI Director, OCB Nguyen Minh Ngan – AI Specialist, OCB Nguyen Manh Tuyen – Head of Data Application, LPBank Securities Vinh Nguyen – Co-Founder \u0026amp; CTO, Ninety Eight Hung Hoang – Customer Solutions Manager, AWS Taiki Dang – Solutions Architect, AWS Key Highlights 1. AWS Cloud Strategy \u0026amp; Amazon Q Market Forecast: By 2026, 85% of large Vietnamese enterprises will have completed or be in the process of migration \u0026amp; modernization. The AI Assistant: Amazon Q Developer is positioned as the core \u0026ldquo;AI pair programmer,\u0026rdquo; supporting the entire lifecycle from coding, testing, and documentation to refactoring and debugging. 2. Real-world Migration Case Studies Techcombank: A massive scale migration case study, modernizing core banking systems on AWS to build a flexible, cost-effective platform. TymeX: Successfully applied the \u0026ldquo;Modernize while migrate\u0026rdquo; strategy, shortening their transformation timeline from 24 months down to 10 months. 3. Amazon Q Developer – The Game Changer Deep Integration: Seamlessly integrated into IDEs, AWS Console, CLI, and DevSecOps pipelines. Capabilities: Automatically generates unit tests, writes documentation, suggests code optimizations, and understands the full codebase context. Live Demo: Refactoring a legacy Java application into a Serverless architecture in just 15 minutes. 4. Modernizing VMware to AWS AWS Transform: A toolset for fast, safe, and cost-optimized migration of legacy VMware workloads. The Playbook: A clear path defined as: Migrate → Landing Zone → Modernize (to EKS, RDS, Serverless). 5. Security at Scale Security-by-Design: Embedding security controls from the development phase (Dev) through to Production. GenAI for Security: Automating detection, response, and remediation using GenAI combined with GuardDuty and Security Hub to maintain an \u0026ldquo;always secure\u0026rdquo; posture as systems scale. Key Takeaways Design Mindset Modernize while Migrate: Don\u0026rsquo;t just \u0026ldquo;lift and shift.\u0026rdquo; Look for opportunities to refactor to cloud-native services (Serverless, Managed DB) during the move to maximize value. Production Readiness: Thinking about Security, Observability, and Cost Optimization is just as important as writing the business logic. Technical Architecture GenAI in SDLC: Leveraging tools like Amazon Q is no longer optional but essential to maintain speed and code quality. Hybrid Cloud Path: Understanding the specific pathway from on-premise (VMware) to Cloud Native (EKS/Lambda). Applying to Work Adopt Amazon Q: Integrate Amazon Q Developer into the IDE (VS Code/IntelliJ) for the Student Management System project to speed up unit test generation and documentation. Serverless First: For new modules of the project, skip EC2 and design directly with AWS Lambda and API Gateway to reduce operational overhead. Refactor Legacy Code: Identify complex or \u0026ldquo;spaghetti\u0026rdquo; code sections in the current project and use Amazon Q to suggest refactoring options. Event Experience Vietnam Cloud Day 2025 provided a comprehensive vision of the industry\u0026rsquo;s future.\nStrategic Insight: Seeing how banks like Techcombank operate gave me a benchmark for what a \u0026ldquo;production-grade\u0026rdquo; system looks like. Tooling Mastery: The live demo of Amazon Q was a highlight, convincing me to adopt AI-assisted coding immediately. Networking: The atmosphere at Bitexco was vibrant, allowing me to connect with senior engineers and understand the high demand for Cloud \u0026amp; AI skills in the local market. Event Photos "},{"uri":"https://sharonng1029.github.io/fcj-fall2025-internship-report/1-worklog/1.2-week2/","title":"Week 2 Worklog","tags":[],"description":"","content":"Week 2 Objectives: Learn about the Storage Service (S3). Learn how to design architecture diagrams on paper. Participate in a technology event. Tasks to be carried out this week: Day Tasks Start Finish References 2 - Learn about Amazon S3:\n+ Bucket \u0026amp; Object\n+ Storage Classes (Standard, Intelligent-Tiering\u0026hellip;)\n+ Bucket Policy \u0026amp; ACL 15/09/2025 15/09/2025 Amazon S3 Overview 3 - Learn AWS architecture diagramming:\n+ Draw.io tool\n+ AWS Official Icon Set 2024\n- Practice: Draw a basic 3-tier Web App model. 16/09/2025 17/09/2025 AWS Architecture Icons 4 - S3 Workshop Practice:\n+ Create an S3 Bucket\n+ Upload HTML/CSS files\n+ Configure Static Website Hosting\n+ Fix Permission errors (403) 17/09/2025 18/09/2025 Host Static Website S3 5 - EVENT: Participate in Vietnam Cloud Day 2025. 18/09/2025 18/09/2025 Vietnam Cloud Day 2025 6 - Write a Summary Report for the Cloud Day event. 19/09/2025 19/09/2025 — Week 2 Achievements: 1. Amazon S3 \u0026amp; Storage:\nUnderstood S3 storage classes for cost optimization. Learned how to configure Bucket Policy for data sharing or protection. Successfully hosted a static website on S3 and accessed it over the Internet. 2. Diagramming Skills:\nBecame proficient with Draw.io using official AWS icons. Drew a basic data flow diagram for a web application. "},{"uri":"https://sharonng1029.github.io/fcj-fall2025-internship-report/5-workshop/5.4-frontend/5.4.3-route53/","title":"Amazon Route53","tags":[],"description":"","content":"ROUTE53 (Custom Domain) 1. Create Hosted Zone Go to AWS Console → Route53 → Create hosted zone Domain name: yourdomain.com Type: Public hosted zone 2. Configure DNS Records A Record for CloudFront:\nRecord name: (empty or www)\rRecord type: A\rAlias: Yes\rRoute traffic to: CloudFront distribution CNAME for Amplify (if not using CloudFront):\nRecord name: app\rRecord type: CNAME\rValue: xxx.amplifyapp.com 3. SSL Certificate (ACM) Go to AWS Console → Certificate Manager Request certificate (must be in region us-east-1 for CloudFront) Domain: yourdomain.com, *.yourdomain.com Validation: DNS validation Add CNAME records to Route53 Summary Page \u0026ldquo;Building a Frontend: Amplify, ROUTE53, CloudFront, WAF\u0026rdquo; full guide:\nCreate a React project with Amplify Use Cognito for frontend authentication Hosting CI/CD via Amplify Frontend connects directly to the serverless backend system, creating a smooth and secure real-time experience.\n"},{"uri":"https://sharonng1029.github.io/fcj-fall2025-internship-report/5-workshop/5.3-backend/5.3.3-amazons3/","title":"Amazon S3","tags":[],"description":"","content":"Amazon S3 S3 is used for:\nSave student avatar\nClassroom materials\nBuild artifacts (React/Vite)\nDeploy website via S3 + CloudFront\nLog \u0026amp; learning material assets\n"},{"uri":"https://sharonng1029.github.io/fcj-fall2025-internship-report/5-workshop/5.3-backend/","title":"Backend Deployment","tags":[],"description":"","content":"Building a Serverless Backend with AWS Lambda, API Gateway, DynamoDB, and Cognito Overview This section guides you through the backend implementation of a serverless student management system on AWS. You will use core services such as DynamoDB for data storage, Lambda for business logic, API Gateway to connect the frontend and backend, and Cognito for user authentication. The implementation process includes designing the data table, configuring authentication, building the backend application with Java Spring Boot, packaging and deploying to Lambda, as well as configuring API Gateway to serve student management tasks in a secure, automated, and scalable way.\nContent Amazon DynamoDB Amazon Cognito Amazon S3 LAMBDA + API GATEWAY "},{"uri":"https://sharonng1029.github.io/fcj-fall2025-internship-report/4-eventparticipated/4.3-event3/","title":"Event 3","tags":[],"description":"","content":"Summary Report: AWS Cloud Mastery Series #1 - ​AI/ML/GenAI on AWS Event Objectives Gain a comprehensive overview of the AI/ML landscape in Vietnam and the AWS ecosystem. Understand the end-to-end Machine Learning lifecycle using Amazon SageMaker. Explore Generative AI capabilities with Amazon Bedrock, focusing on Foundation Models (FMs), RAG, and Agents. Learn practical techniques for Prompt Engineering and building AI-powered applications without deep data science expertise. Time \u0026amp; Venue Time: 08:30 – 12:00, Saturday, November 15 2025\nVenue: 26th Floor, Bitexco Financial Tower, 2 Hai Trieu Street, Ben Nghe Ward, District 1, Ho Chi Minh City\nSpeakers Dinh Le Hoang Anh – Cloud Engineer Trainee, First Cloud AI Journey Lam Tuan Kiet – Sr. DevOps Engineer, FPT Software Danh Hoang Hieu Nghi – AI Engineer, Renova Cloud Key Highlights 1. AWS AI/ML Services Overview (SageMaker) End-to-end Platform: Amazon SageMaker is not just for training; it covers the entire lifecycle from data preparation (Data Wrangler) to deployment and monitoring. MLOps Integration: The importance of integrating ML workflows with DevOps practices (CI/CD for ML) to ensure reproducible and scalable model deployment. Live Demo: A walkthrough of SageMaker Studio, demonstrating how to label data, train a model, and deploy an endpoint in a unified interface. 2. Generative AI with Amazon Bedrock Serverless GenAI: Bedrock allows access to high-performing Foundation Models (Claude 3, Llama 3, Titan) via a single API, removing the need to manage infrastructure. Model Selection: Guidance on choosing the right model based on cost, latency, and reasoning capability (e.g., using Claude for complex reasoning vs. Titan for simple summarization). Retrieval-Augmented Generation (RAG): The architecture for connecting LLMs to private data (Knowledge Bases) to reduce hallucinations and provide accurate, context-aware answers. 3. Advanced GenAI Features Prompt Engineering: Techniques like Chain-of-Thought and Few-shot learning to steer model behavior effectively. Bedrock Agents: Building multi-step workflows where the AI can execute API calls to perform tasks (e.g., booking a meeting, querying a database). Guardrails: Implementing safety filters to prevent the generation of harmful or inappropriate content. Key Takeaways Design Mindset Democratization of AI: You don\u0026rsquo;t need to be a PhD in Math to use AI. With services like Bedrock, software engineers can integrate powerful AI features via APIs. Context is King: A generic model is less useful than a model grounded in your specific business data. RAG is the bridge between generic intelligence and business value. Technical Architecture Managed Services vs. Self-hosted: For most use cases, using managed services (Bedrock/SageMaker) is more cost-effective and secure than hosting open-source models on EC2 instances. Safety First: AI applications must have guardrails (input/output filtering) before reaching end-users. Applying to Work Explore RAG Concepts: Research the RAG (Retrieval-Augmented Generation) architecture to understand the theoretical foundation of smart document search features. Understand Data Privacy: Learn the core principles of data protection (e.g., avoiding sending sensitive data to public models) to apply in future projects. Data Privacy: Ensure that any student data used for RAG follows strict encryption standards (KMS) and is not used to train public base models. Event Experience The workshop successfully demystified the complex world of AI/ML.\nPerspective Diversity: Hearing from a Senior DevOps Engineer (FPT) and an AI Engineer (Renova) provided a balanced view between operationalizing AI and building AI models. Practicality: The \u0026ldquo;Live Demo\u0026rdquo; of building a GenAI chatbot was incredibly valuable. It showed that building a functional prototype can take hours, not months. Networking: The ice-breaker activity and networking session allowed me to discuss the current demand for \u0026ldquo;AI-literate developers\u0026rdquo; in the Vietnamese market. Some Event Photos This event bridged the gap between traditional software development and modern AI. It confirmed that integrating GenAI is the next logical step for enhancing the user experience in my current projects.\n"},{"uri":"https://sharonng1029.github.io/fcj-fall2025-internship-report/3-blogstranslated/","title":"Translated Blogs","tags":[],"description":"","content":"Blog 1 - Introducing Strands Agents, an Open Source AI Agents SDK Strands Agents is an open-source SDK that simplifies building and deploying AI agents using a model-driven approach, requiring just a few lines of code. It powers production systems at AWS teams like Amazon Q Developer and AWS Glue, enabling faster development from months to days while leveraging LLMs for planning, tool calls, and reflection. Key features include seamless tool integration (20+ pre-built tools and thousands via MCP), support for multiple models (Bedrock, Claude, Llama, Ollama), and production-ready deployment on AWS services with OpenTelemetry observability.\nBlog 2 - Introducing managed accounting for AWS Parallel Computing Service AWS Parallel Computing Service (PCS) introduces managed accounting to simplify HPC management with Slurm, offering resource monitoring, usage limits, and project attribution for chargeback and budgeting. This eliminates the need for separate databases, providing clear visibility into \u0026ldquo;who did what\u0026rdquo; for better reporting and capacity planning. Enable it during cluster setup with Slurm 24.11+, configure via console, and leverage use cases like job attribution, CPU limits to prevent hoarding, utilization reports, and failure analysis. Pricing includes hourly fees by cluster size plus GB-month storage—start in the AWS PCS console for efficient, scalable HPC operations.\nBlog 3 - Simplify AWS AppSync Events integration with Powertools for AWS Lambda AWS AppSync Events powers real-time WebSocket features, and the latest Powertools for AWS Lambda introduces AppSyncEventsResolver for Python, TypeScript, and .NET—streamlining event handling with pattern routing, filtering, transformation, and error management. Set up handlers for PUBLISH and SUBSCRIBE using intuitive channels and wildcards, slashing boilerplate code while ensuring robust authorization, full event access, and optimized aggregation. This lets developers focus on business logic without Lambda disruptions, perfect for chat apps, live dashboards, or IoT systems—boosting performance in real-time experiences.\n"},{"uri":"https://sharonng1029.github.io/fcj-fall2025-internship-report/1-worklog/1.3-week3/","title":"Week 3 Worklog","tags":[],"description":"","content":"Week 3 Objectives: Master the Compute service (EC2). Understand High-Performing Architectures (Scaling, Load Balancing). Tasks to be carried out this week: Day Tasks Start Finish References 2 - Learn EC2 basics:\n+ Instance types (General, Compute, Memory optimized)\n+ AMI (Amazon Machine Image)\n+ Key Pair 22/09/2025 22/09/2025 EC2 Instance Types 3 - Learn EBS (Elastic Block Store):\n+ Volume types (gp2, gp3, io1)\n+ Snapshot \u0026amp; Backup\n- Learn Security Groups (virtual firewall). 23/09/2025 24/09/2025 EBS Volume Types 4 - Learn High-Performing Architectures:\n+ Elastic Load Balancing (ELB)\n+ EC2 Auto Scaling\n+ Vertical vs Horizontal Scaling 24/09/2025 24/09/2025 ELB Product Page 5 - Lab Practice:\n+ Launch EC2 Linux\n+ SSH remote access\n+ Install Web Server (Apache/Nginx)\n+ Create ALB for traffic load 25/09/2025 25/09/2025 EC2 Getting Started 6 - Review EC2 \u0026amp; EBS knowledge learned.\n- Summarize common SSH connection issues. 26/09/2025 26/09/2025 — Week 3 Achievements: 1. Amazon EC2 \u0026amp; Compute:\nDistinguished EC2 Instance Types (T, M, C, R) for optimal performance/cost. Understood EC2 Instance lifecycle (Pending → Running → Stopping → Terminated). Managed EBS Volumes: create, attach, and backup using snapshots. 2. High Performance \u0026amp; Scalability:\nUnderstood the role of Load Balancer in traffic distribution. Understood how Auto Scaling Group helps scale during high load. Successfully SSH’ed into a server and installed a basic web application. "},{"uri":"https://sharonng1029.github.io/fcj-fall2025-internship-report/5-workshop/5.4-frontend/","title":"Frontend Development","tags":[],"description":"","content":"Building a Secure Frontend with AWS Amplify, CloudFront, WAF, and Route53 Overview In this section, you will build a web interface for the Serverless Student Management System using AWS Amplify, CLOUDFRONT, WAF, and ROUTE53.\nFrontend provides the following functions:\nOverall architecture:\nContent Amazon Amplify Amazon CloudFront \u0026amp; WAF Amazon Route53 "},{"uri":"https://sharonng1029.github.io/fcj-fall2025-internship-report/5-workshop/5.3-backend/5.3.4-lambdaapigateway/","title":"LAMBDA + API GATEWAY","tags":[],"description":"","content":"LAMBDA + GATEWAY API (Backend) 1. Prepare Java Spring for Lambda Add dependencies to pom.xml:\n\u0026lt;dependencies\u0026gt; \u0026lt;!-- AWS Lambda --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.amazonaws.serverless\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;aws-serverless-java-container-springboot3\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.0.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- AWS SDK --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;software.amazon.awssdk\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;dynamodb\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.21.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;build\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-shade-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.5.0\u0026lt;/version\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;phase\u0026gt;package\u0026lt;/phase\u0026gt; \u0026lt;goals\u0026gt;\u0026lt;goal\u0026gt;shade\u0026lt;/goal\u0026gt;\u0026lt;/goals\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt; Create Lambda Handler:\n// src/main/java/com/example/StreamLambdaHandler.java package com.example; import com.amazonaws.serverless.exceptions.ContainerInitializationException; import com.amazonaws.serverless.proxy.model.AwsProxyRequest; import com.amazonaws.serverless.proxy.model.AwsProxyResponse; import com.amazonaws.serverless.proxy.spring.SpringBootLambdaContainerHandler; import com.amazonaws.services.lambda.runtime.Context; import com.amazonaws.services.lambda.runtime.RequestStreamHandler; import java.io.IOException; import java.io.InputStream; import java.io.OutputStream; public class StreamLambdaHandler implements RequestStreamHandler { private static SpringBootLambdaContainerHandler\u0026lt;AwsProxyRequest, AwsProxyResponse\u0026gt; handler; static { try { handler = SpringBootLambdaContainerHandler.getAwsProxyHandler(Application.class); } catch (ContainerInitializationException e) { throw new RuntimeException(\u0026#34;Could not initialize Spring Boot application\u0026#34;, e); } } @Override public void handleRequest(InputStream inputStream, OutputStream outputStream, Context context) throws IOException { handler.proxyStream(inputStream, outputStream, context); } } 2. Build JAR cd backend-project mvn clean package -DskipTests # Output: target/your-app.jar 3. Create Lambda Function Go to AWS Console → Lambda → Create function Configuration: Function name: student-management-api Runtime: Java 17 Architecture: x86_64 Memory: 512 MB (or 1024 MB for better performance) Timeout: 30 seconds Upload JAR file or from S3 Handler: com.example.StreamLambdaHandler::handleRequest 4. Configure IAM Role for Lambda Attach policies:\nAmazonDynamoDBFullAccess AWSLambdaBasicExecutionRole AmazonCognitoPowerUser 5. Create API Gateway Go to AWS Console → API Gateway → Create API Select HTTP API (recommended) or REST API Configuration: API name: student-management-api Integration: Lambda function Route: ANY /{proxy+} Enable CORS: Access-Control-Allow-Origin: * (or specific domain) Access-Control-Allow-Methods: GET, POST, PUT, PATCH, DELETE, OPTIONS Access-Control-Allow-Headers: Content-Type, Authorization Deploy API: Create stage: prod Save Invoke URL: https://xxxxxxxx.execute-api.ap-southeast-1.amazonaws.com/prod Summary This section guides you through the implementation of a backend for a serverless student management system on AWS, using key services such as DynamoDB, Lambda, API Gateway, and Cognito. You have practiced:\nDesigning and creating DynamoDB tables to store student, class, subject, and notification data, and configuring GSI to optimize queries. Setting up Cognito User Pool to authenticate and authorize users. Using S3 to store avatars, class materials, and build artifacts. Building a backend with Java Spring Boot, packaging the application into a JAR, and deploying it to Lambda. Configuring IAM Roles for Lambda to ensure necessary service access. Create and configure API Gateway to connect frontend with backend, fully support HTTP methods and CORS security. This process helps you build a modern, automated, scalable and secure backend, fully meeting student management tasks on AWS platform.\n"},{"uri":"https://sharonng1029.github.io/fcj-fall2025-internship-report/4-eventparticipated/4.4-event4/","title":"Event 4","tags":[],"description":"","content":"Summary Report: AWS Cloud Mastery Series #2 – DevOps on AWS Event Objectives Understand the core principles of DevOps culture and key performance metrics (DORA). Master the AWS DevOps ecosystem for building end-to-end CI/CD pipelines. Compare and select appropriate Infrastructure as Code (IaC) tools (CloudFormation vs. AWS CDK). Explore containerization strategies using Amazon ECS, EKS, and App Runner. Implement full-stack observability using CloudWatch and AWS X-Ray. Time \u0026amp; Venue Time: 08:30 – 17:00, Monday, November 17, 2025\nVenue: 26th Floor, Bitexco Financial Tower, 2 Hai Trieu Street, Ben Nghe Ward, District 1, Ho Chi Minh City\nSpeakers Truong Quang Tinh - DevOps Engineer, TymeX | AWS Community Builder Kha Van - Cloud Security Engineer | AWS Community Builders Bao Huynh – AWS Community Builder Thinh Nguyen – AWS Community Builder Vi Tran – AWS Community Builder Key Highlights 1. DevOps Culture \u0026amp; Metrics Cultural Shift: Moving from siloed development and operations to a unified culture of shared responsibility. Key Metrics (DORA): Focusing on four critical indicators to measure performance: Deployment Frequency (DF) Lead Time for Changes (LT) Mean Time to Restore (MTTR) Change Failure Rate (CFR) 2. AWS DevOps Services – CI/CD Pipeline Source Control: Strategies for Git management (GitFlow vs. Trunk-based development) using AWS CodeCommit. Orchestration: Automating the release process with AWS CodePipeline. Deployment Strategies: Blue/Green: Reduces downtime and risk by running two identical environments. Canary: Rolls out changes to a small subset of users first. Rolling: Updates instances incrementally. 3. Infrastructure as Code (IaC) AWS CloudFormation: The declarative approach using JSON/YAML templates to define infrastructure; utilizes drift detection to maintain state consistency. AWS CDK (Cloud Development Kit): The imperative approach allowing developers to define cloud resources using familiar programming languages (TypeScript, Python, Java). CDK constructs allow for reusable infrastructure patterns. 4. Container Services \u0026amp; Observability Compute Evolution: Selection criteria between Amazon ECS (tight control), Amazon EKS (Kubernetes standard), and AWS App Runner (simplified for developers). Observability: Going beyond simple monitoring by integrating CloudWatch (Logs, Metrics, Alarms) with AWS X-Ray for distributed tracing, enabling root-cause analysis in microservices. Key Takeaways Design Mindset Automation First: Manual processes are error-prone; everything from testing to infrastructure provisioning should be automated. Shift-Left Security: Integrating security checks early in the CI/CD pipeline rather than at the end. Measure Everything: You cannot improve what you do not measure. DORA metrics are the compass for DevOps maturity. Technical Architecture Immutable Infrastructure: Servers are never modified after deployment; they are replaced. Pipeline Orchestration: A robust pipeline must include build, unit test, integration test, and approval gates before production deployment. Traceability: In distributed systems, correlating logs and traces (via X-Ray) is mandatory for debugging. Modernization Strategy Right-sizing Compute: Use App Runner for simple web apps to reduce operational overhead, and reserve EKS for complex, orchestrated microservices. IaC Adoption: Moving away from manual console clicks to code-defined infrastructure to ensure reproducibility and disaster recovery. Applying to Work Adopt Trunk-based Development: Streamline the git workflow in the team project to reduce merge conflicts and accelerate integration. Implement CI/CD: Build a pipeline using AWS CodePipeline that automatically deploys the student management backend upon pushing to the main branch. Migrate to IaC: Refactor the current manual setup of DynamoDB and Lambda functions into AWS CDK scripts for better maintainability. Enhance Monitoring: Set up CloudWatch Alarms for critical API errors (5xx) to proactively detect issues before the demo. Event Experience Attending the “DevOps on AWS” workshop was instrumental in bridging the gap between coding and operations. It provided a roadmap for building reliable, scalable systems. Key experiences included:\nLearning from practitioners: The speakers, being active AWS Community Builders, shared \u0026ldquo;war stories\u0026rdquo; and real-world pitfalls in DevOps, not just textbook theory. I gained clarity on the Shared Responsibility Model within a DevOps context. Hands-on technical exposure: Participated in a live CI/CD walkthrough, witnessing raw code transform into a deployed application via an automated pipeline in minutes. Experienced the power of AWS CDK by deploying a VPC and ECS cluster with significantly fewer lines of code compared to raw CloudFormation templates. Visualized distributed tracing with AWS X-Ray, understanding how to pinpoint latency bottlenecks in microservices. Networking and discussions: Engaged in discussions about the trade-offs between GitFlow and Trunk-based development for small teams and received guidance on the AWS Certified DevOps Engineer – Professional certification roadmap. Lessons learned IaC is non-negotiable: For any long-term project, infrastructure must be code. Observability is crucial: Building a system is half the battle; knowing it is healthy is the other half. Culture over tools: Tools like Jenkins or CodePipeline are useless without a culture of collaboration and continuous improvement. Some event photos Overall, the event not only provided technical skills in AWS tools but also instilled a professional DevOps mindset, preparing me to build production-grade systems efficiently.\n"},{"uri":"https://sharonng1029.github.io/fcj-fall2025-internship-report/1-worklog/1.4-week4/","title":"Week 4 Worklog","tags":[],"description":"","content":"Week 4 Objectives: Deep dive into Networking (VPC). Learn about Resilient Architectures. Tasks to be carried out this week: Day Tasks Start Finish References 2 - Learn VPC (Virtual Private Cloud):\n+ CIDR Block\n+ Subnet (Public vs Private)\n+ Route Table 29/09/2025 30/09/2025 What is Amazon VPC? 3 - Learn connectivity components:\n+ Internet Gateway (IGW)\n+ NAT Gateway\n- Practice: Design a Custom VPC from scratch. 30/09/2025 01/10/2025 VPC Scenarios 4 - Learn Resilient Architectures:\n+ Multi-AZ deployment\n+ Backup \u0026amp; Restore\n+ Route 53 (DNS \u0026amp; Failover) 01/10/2025 01/10/2025 Disaster Recovery 5 - Practice:\n+ Configure Route Table for Public/Private subnet\n+ Test Internet from Private Subnet via NAT 02/10/2025 02/10/2025 — 6 - Translate 3 technical blogs (VPC, Serverless, Security).\n- Summarize Networking module. 03/10/2025 03/10/2025 AWS Blogs Week 4 Achievements: 1. Networking (VPC):\nUnderstood packet flow inside AWS networking. Differentiated Security Group (instance-level) vs NACL (subnet-level). Designed a secure network architecture: Web Server in Public Subnet, DB in Private Subnet. 2. Resilient Architectures:\nMastered Multi-AZ concept for High Availability. Understood NAT Gateway usage to secure backend instances. Completed translation of technical documents for deeper understanding. "},{"uri":"https://sharonng1029.github.io/fcj-fall2025-internship-report/4-eventparticipated/","title":"Events Attended","tags":[],"description":"","content":"During the First Cloud Journey internship (08/09/2025 – 28/12/2025), I actively participated in five professional events organized by AWS Vietnam and its partners. These events not only helped me stay updated with the latest technology trends but also expanded my network and strengthened my practical knowledge.\nEvent 1 Event Name: Kick-off AWS First Cloud Journey Workforce – OJT FALL 2025\nTime: 08:30 – 12:00, Saturday, 06/09/2025\nLocation: 26th Floor, Bitexco Financial Tower, 2 Hai Trieu Street, Ben Nghe Ward, District 1, Ho Chi Minh City\nRole: Attendee\nEvent 2 Event Name: Vietnam Cloud Day 2025 – Ho Chi Minh City Connect Edition for Builders\nTime: 09:00 – 17:00, Thursday, 18/09/2025\nLocation: 36th Floor, Bitexco Financial Tower, 2 Hai Trieu Street, Ben Nghe Ward, District 1, Ho Chi Minh City\nRole: Attendee (participated in track: Migration \u0026amp; Modernization track)\nEvent 3 Event Name: AWS Cloud Mastery Series #1 – AI/ML \u0026amp; Generative AI\nTime: 08:30 – 12:00, Saturday, 15/11/2025\nLocation: 26th Floor, Bitexco Financial Tower, 2 Hai Trieu Street, Ben Nghe Ward, District 1, Ho Chi Minh City\nRole: Attendee\nEvent 4 Event Name: AWS Cloud Mastery Series #2 – DevOps on AWS\nTime: 08:30 – 17:00, Monday, 17/11/2025\nLocation: 26th Floor, Bitexco Financial Tower, 2 Hai Trieu Street, Ben Nghe Ward, District 1, Ho Chi Minh City\nRole: Attendee\nEvent 5 Event Name: AWS Cloud Mastery Series #3 – Cloud Security Best Practices\nTime: 08:30 – 12:00, Saturday, 29/11/2025\nLocation: 26th Floor, Bitexco Financial Tower, 2 Hai Trieu Street, Ben Nghe Ward, District 1, Ho Chi Minh City\nRole: Attendee\n"},{"uri":"https://sharonng1029.github.io/fcj-fall2025-internship-report/5-workshop/5.5-ci-cd/","title":"CI/CD Pipeline","tags":[],"description":"","content":"Overview This section guides you through setting up an automated CI/CD process for your Serverless Student Management System on AWS. You will use services like Amazon S3 to store artifacts, AWS CodeBuild to build frontend and backend applications, and AWS CodePipeline to automate the entire build, test, and deploy process. Applying CI/CD helps ensure that applications are always updated quickly, minimize manual errors, and improve the efficiency of developing and operating systems on the AWS platform.\nOverview diagram:\n1. Create S3 Bucket for Artifacts Bucket name: student-management-artifacts-{account-id}\rRegion: ap-southeast-1\rVersioning: Enabled 2. Create CodeBuild Project Go to AWS Console → CodeBuild → Create build project Frontend Build:\nProject name: student-management-frontend-build\rSource: GitLab (or GitHub)\rEnvironment:\r- Managed images\r- Operating system: Ubuntu\r- Runtime: Standard\r- Image: aws/codebuild/standard:7.0\rBuildspec: Use buildspec file buildspec-frontend.yml:\nversion: 0.2 phasing: install: runtime-versions: nodejs: 18 commands: - cd serverless-student-management-system-front-end - npm ci build: commands: - npm run build artifacts: files: - \u0026#39;**/*\u0026#39; base-directory: serverless-student-management-system-front-end/build cache: paths: - \u0026#39;serverless-student-management-system-front-end/node_modules/**/*\u0026#39; Backend Build:\nProject name: student-management-backend-build buildspec-backend.yml:\nversion: 0.2 phasing: install: runtime-versions: java: corretto17 build: commands: - cd backend-project - mvn clean package -DskipTests artifacts: files: - backend-project/target/*.jar - appspec.yml discard-paths: no cache: paths: - \u0026#34;/root/.m2/**/*\u0026#34; 3. Create CodePipeline Go to AWS Console → CodePipeline → Create pipeline Pipeline settings:\nPipeline name: student-management-pipeline Service role: New service role Source stage:\nSource provider: GitLab (or GitHub) Repository: your-repo Branch: main Change detection: GitLab webhooks Build stage:\nBuild provider: AWS CodeBuild Project name: student-management-frontend-build Deploy stage:\nDeploy provider: Amazon S3 (for frontend artifacts) Or: AWS Amplify (if using Amplify) Summary Through this section, you have learned how to set up an automated CI/CD process for the Serverless Student Management System using AWS services such as S3, CodeBuild, and CodePipeline. You have practiced creating an S3 bucket to store artifacts, configuring build projects for the frontend and backend, as well as building a pipeline to automate the entire build, test, and deploy process. Applying CI/CD helps ensure the system is always updated, deployed quickly, minimizes manual errors, and improves software development efficiency.\n"},{"uri":"https://sharonng1029.github.io/fcj-fall2025-internship-report/5-workshop/","title":"Workshop","tags":[],"description":"","content":"Serverless Student Management System on AWS Overview Serverless Student Management Platform is a cloud-based student management solution, cost-effective and flexible scalability thanks to the use of AWS Serverless services (Lambda, DynamoDB, API gateway\u0026hellip;). The platform supports up to 50-100 students initially, with the ability to flexibly expand to 500–1000 students without major infrastructure changes.\nCore services: API Gateway (REST), Lambda handles business logic, DynamoDB stores data, Amplify (frontend React), Cognito (user authentication), CloudWatch (monitoring), combined with modern DevOps CI/CD processes.\nContents System Overview and Architecture Environment Preparation \u0026amp; AWS Account Setup Backend Deployment: DynamoDB, Lambda, API Gateway, Cognito Frontend Development: Amplify, Route 53, CloudFront, WAF CI/CD_Pipeline CloudWatch Clean up Experience Objectives Understand and implement multi-tier serverless architecture on AWS, operate with key services. Master authorization and user authentication with Cognito. Practice building CRUD functions. Experience modern DevOps process: automate build, test, deploy through CI/CD pipeline. "},{"uri":"https://sharonng1029.github.io/fcj-fall2025-internship-report/4-eventparticipated/4.5-event5/","title":"Event 5","tags":[],"description":"","content":"Summary Report: AWS Cloud Mastery Series #3 - ​Theo AWS Well-Architected Security Pillar Event Objectives Deeply understand the Security Pillar within the AWS Well-Architected Framework. Master the core principles: Least Privilege, Zero Trust, and Defense in Depth. Learn how to implement security controls across 5 key areas: IAM, Detection, Infrastructure Protection, Data Protection, and Incident Response. Identify top security threats in the cloud environment specifically for the Vietnamese market. Time \u0026amp; Venue Time: 08:30 – 12:00, Saturday, November 29, 2025\nVenue: 26th Floor, Bitexco Financial Tower, 2 Hai Trieu Street, Ben Nghe Ward, District 1, Ho Chi Minh City\nSpeakers Le Vu Xuan An - Software \u0026amp; Cloud Engineer | AWS Cloud Club Captain HCMUTE Tran Doan Cong Ly - DevOps Engineer | AWS FCAJ Ambassador | AWS Cloud Club Captain PTIT Danh Hoang Hieu Nghi – AI Engineer, Renova Cloud | AWS First Cloud AI Journey | AWS Cloud Club Captain HUFLIT Tran Duc Anh - Cloud Security Engineer Trainee | First Cloud AI Journey | AWS Cloud Club Captain SGU Nguyen Tuan Thinh - Cloud Engineer Trainee | First Cloud AI Journey Nguyen Do Thanh Dat - Cloud Engineer Trainee | First Cloud AI Journey Đinh Le Hoang Anh – Cloud Engineer Trainee | First Cloud AI Journey Kha Van - Cloud Security Engineer | AWS Community Builders Special Guest:\nMendel Grabski - Cloud Security \u0026amp; Solution Architect | Enabling Secure-by-Design Solutions Truong Quang Tinh - DevOps Engineer, TymeX | AWS Community Builder Key Highlights 1. Security Foundations \u0026amp; Identity (IAM) Core Principles: Moved beyond perimeter security to a Zero Trust model where every request must be authenticated and authorized. Modern IAM: Transition from long-term credentials (IAM Users with Access Keys) to temporary credentials via IAM Roles and Identity Center (SSO). Enforcing Least Privilege using Access Analyzer to validate policies. Multi-Account Strategy: Using SCPs (Service Control Policies) to set permission boundaries across the organization. 2. Detection \u0026amp; Continuous Monitoring Centralized Visibility: utilizing Security Hub to aggregate alerts from GuardDuty, Inspector, and Macie. Logging Strategy: Enabling logs at all layers is non-negotiable (VPC Flow Logs for network, CloudTrail for API calls, S3 Server Access Logs). Detection-as-Code: Defining alert rules as code to ensure consistent monitoring across environments. 3. Infrastructure \u0026amp; Data Protection Network Security: Implementing Defense in Depth with VPC segmentation (Public/Private subnets), Security Groups (stateful), and WAF/Shield for edge protection. Encryption: At-rest: Using KMS with automatic key rotation for EBS, RDS, and S3. In-transit: Enforcing TLS 1.2+ for all data movement. Secrets Management: replacing hardcoded credentials in code with AWS Secrets Manager or Parameter Store. 4. Incident Response (IR) Automation IR Lifecycle: Preparation → Detection \u0026amp; Analysis → Containment, Eradication \u0026amp; Recovery → Post-Incident Activity. Playbooks: Detailed walkthroughs for handling common scenarios like compromised IAM keys or public S3 buckets. Automation: Using Lambda and Step Functions to auto-remediate issues (e.g., automatically revoking a compromised user\u0026rsquo;s session). Key Takeaways Security Mindset Security is everyone\u0026rsquo;s responsibility: It is not just for the security team; developers must practice \u0026ldquo;Security by Design\u0026rdquo;. Assume Breach: Always design systems assuming that a component might be compromised, limiting the \u0026ldquo;blast radius\u0026rdquo;. Technical Architecture Identity as the new perimeter: In a cloud-native world, IAM is more critical than the network firewall. Immutable Infrastructure: Patching servers in place is risky; prefer replacing them with new, patched images to prevent malware persistence. Applying to Work Refactor IAM: Immediately review the group project\u0026rsquo;s IAM policies. Remove any *:* permissions and replace hardcoded Access Keys with IAM Roles for EC2/Lambda. Secure Secrets: Migrate database credentials from .env files to AWS Systems Manager Parameter Store. Enable GuardDuty: Activate GuardDuty in the project account to detect anomalies (cryptojacking, unauthorized access) during the development phase. Encryption: Enable default encryption (SSE-S3) for all S3 buckets used in the Student Management System project. Event Experience The workshop provided a concentrated, high-intensity dive into cloud security. Unlike general overviews, this session focused on actionable patterns:\nInteractive Learning: The mini-demo on validating IAM Policies and simulating access helped visualize how easily permissions can be misconfigured. Real-world relevance: Discussing \u0026ldquo;Top threats in Vietnam\u0026rdquo; made the content highly relatable, emphasizing the need to protect against common misconfigurations and credential leaks. Practical Automation: Seeing an automated IR playbook triggered by EventBridge and executed by Lambda changed my perspective on how to handle security incidents at scale. Some Event Photos This event shifted my perspective from \u0026ldquo;building it fast\u0026rdquo; to \u0026ldquo;building it secure.\u0026rdquo; I now have a clear roadmap to harden our applications before they reach production.\n"},{"uri":"https://sharonng1029.github.io/fcj-fall2025-internship-report/1-worklog/1.5-week5/","title":"Week 5 Worklog","tags":[],"description":"","content":"Week 5 Objectives: Learn Database Services. Explore AWS Well-Architected Framework. Kick off the Project idea. Tasks to be carried out this week: Day Tasks Start Finish References 2 - Learn Database:\n+ RDS (SQL: MySQL, PostgreSQL)\n+ DynamoDB (NoSQL, Serverless)\n+ Compare use cases 06/10/2025 07/10/2025 AWS Databases 3 - Learn AWS Well-Architected Framework:\n+ 6 pillars (Operational Excellence, Security, Reliability, Performance, Cost, Sustainability)\n- Study sample architecture diagrams. 07/10/2025 08/10/2025 Well-Architected Tool 4 - Project brainstorming.\n- Analyze existing architecture models. 08/10/2025 08/10/2025 — 5 - Practice:\n+ Create RDS Instance\n+ Connect EC2 to RDS (configure Security Group) 09/10/2025 09/10/2025 RDS User Guide 6 - Research Serverless concepts (Lambda, API Gateway) for the project direction. 10/10/2025 10/10/2025 Serverless on AWS Week 5 Achievements: 1. Database \u0026amp; Architecture:\nUnderstood when to use Relational DB (RDS) vs Non-relational DB (DynamoDB). Understood the 6 pillars of the Well-Architected Framework. Successfully connected a 2-tier model (App + DB). 2. Project:\nStarted team workflow and requirement analysis. Defined initial direction using Serverless architecture. "},{"uri":"https://sharonng1029.github.io/fcj-fall2025-internship-report/5-workshop/5.6-cloud-watch/","title":"Cloud Watch","tags":[],"description":"","content":"Overview This section guides you through using Amazon CloudWatch to monitor, alert, and manage services in the Serverless Student Management System on AWS. You will learn how to create log groups for Lambda, set up alarms for Lambda errors and performance, API Gateway, and build a visual dashboard to track the entire system\u0026rsquo;s operations. Proactive monitoring helps detect problems early, optimize operations, and effectively control AWS costs.\nCloudWatch (Monitoring) 1. Create Log Groups Lambda automatically creates log group: /aws/lambda/student-management-api\n2. Create Alarms Go to CloudWatch → Alarms → Create alarm Lambda Error Alarm:\nMetric: AWS/Lambda → Errors\rFunction: student-management-api\rStatistics: Sum\rPeriod: 5 minutes\rThreshold: \u0026gt; 5 API Gateway 5xx Alarm:\nMetric: AWS/ApiGateway → 5XXError\rStatistics: Sum\rPeriod: 5 minutes\rThreshold: \u0026gt; 10 3. Create Dashboard Go to CloudWatch → Dashboards → Create dashboard Add widgets: Lambda invocations Lambda errors Lambda duration API Gateway requests DynamoDB read/write capacity Summary Through this section, you have learned how to use Amazon CloudWatch to monitor, alert, and effectively manage AWS services in a serverless system. Setting up log groups, alarms, and dashboards helps you detect problems early, optimize operations, control costs, and ensure the system always operates stably and securely. This is an important step to maintain service quality and support long-term operations on the AWS platform.\n"},{"uri":"https://sharonng1029.github.io/fcj-fall2025-internship-report/6-self-evaluation/","title":"Self-Assessment","tags":[],"description":"","content":"From September 08, 2025 to December 28, 2025, I had the honor of participating in the First Cloud Journey program organized by AWS Vietnam. This was an invaluable opportunity for me to gain hands-on experience with cloud technology, contribute to building and deploying solutions on the AWS platform, and work alongside experienced mentors and talented fellow interns.\nThrough weeks of learning, hands-on practice, and the execution of our group project — Serverless Student Management System, a fully serverless student management platform (similar to university LMS systems) — I significantly strengthened and expanded my knowledge of AWS services including Route 53, Cognito, Amplify, WAF, API Gateway, DynamoDB, S3, EventBridge, AppSync (GraphQL), SES, CloudFront, and CloudWatch. At the same time, I improved my programming skills, teamwork abilities, presentation skills, and gained practical experience working with GitLab.\nRegarding work attitude, I consistently maintained a serious learning mindset, fully complied with the program’s rules and processes, proactively collaborated with team members, and strictly respected deadlines and established workflows.\nTo objectively reflect on my internship period, I would like to evaluate myself based on the following criteria:\nNo. Criteria Description Excellent Good Average 1 Professional knowledge \u0026amp; skills Understanding of the field, applying knowledge in practice, proficiency with tools, work quality ☐ ✅ ☐ 2 Ability to learn Ability to absorb new knowledge and learn quickly ☐ ✅ ☐ 3 Proactiveness Taking initiative, seeking out tasks without waiting for instructions ✅ ☐ ☐ 4 Sense of responsibility Completing tasks on time and ensuring quality ✅ ☐ ☐ 5 Discipline Adhering to schedules, rules, and work processes ✅ ☐ ☐ 6 Progressive mindset Willingness to receive feedback and improve oneself ✅ ☐ ☐ 7 Communication Presenting ideas and reporting work clearly ☐ ☐ ✅ 8 Teamwork Working effectively with colleagues and participating in teams ☐ ✅ ☐ 9 Professional conduct Respecting colleagues, partners, and the work environment ✅ ☐ ☐ 10 Problem-solving mindset Identifying problems, proposing solutions, and showing creativity ☐ ✅ ☐ 11 Contribution to project/organization Work effectiveness, improvement initiatives, and Work effectiveness, innovative ideas, recognition from the team ☐ ✅ ☐ 12 Overall General evaluation of the entire internship period ☐ ✅ ☐ Areas for Future Improvement Further strengthen personal discipline, especially regarding punctuality and time management, particularly under high-pressure deadlines toward the end of the program. Enhance presentation skills and professional English communication in an international working environment. Develop stronger systems thinking and advanced debugging capabilities to resolve production-level issues more quickly and accurately. Take a more proactive role in code reviews and knowledge-sharing sessions to build technical leadership skills in the future. The First Cloud Journey program has truly been a major milestone in my academic and professional journey. I am deeply grateful to AWS Vietnam, the mentors, and my teammates for their guidance and companionship throughout this meaningful period.\n"},{"uri":"https://sharonng1029.github.io/fcj-fall2025-internship-report/1-worklog/1.6-week6/","title":"Week 6 Worklog","tags":[],"description":"","content":"Week 6 Objectives: Learn Decoupling \u0026amp; Advanced Security. Evaluate Project ideas. Tasks to be carried out this week: Day Tasks Start Finish References 2 - Learn Application Integration:\n+ SQS (Message Queue)\n+ SNS (Pub/Sub Notification) 13/10/2025 14/10/2025 SQS vs SNS 3 - Learn Secure Architectures (Part 2):\n+ Encryption (KMS)\n+ Secrets Manager (credential management)\n+ GuardDuty (threat detection) 14/10/2025 15/10/2025 AWS KMS 4 - Learn AWS Amplify (Hosting \u0026amp; Auth).\n- Evaluate pros/cons of project ideas. 15/10/2025 15/10/2025 Amplify Framework 5 - Search for Reference Architecture for the topic “Student Management”. 16/10/2025 16/10/2025 — 6 - Research more best practices for Serverless architectures. 17/10/2025 17/10/2025 — Week 6 Achievements: 1. Advanced Architecture:\nUnderstood how Decoupled Architecture improves scalability and flexibility. Learned encryption basics using KMS (at rest / in transit). Understood secure credential management with Secrets Manager. 2. Project:\nIdentified potential Frontend technology (Amplify). Narrowed down project idea scope. "},{"uri":"https://sharonng1029.github.io/fcj-fall2025-internship-report/5-workshop/5.7-clean-up/","title":"Clean Up","tags":[],"description":"","content":"Congratulations on successfully deploying the entire Serverless Student Management system!\nTo avoid unnecessary charges on your AWS account, follow the Clean Up steps below in top-to-bottom order (the reverse order of creation).\n1. Delete CodePipeline \u0026amp; CodeBuild Projects Go to CodePipeline → Select the pipeline student-management-pipeline → Release change (if it’s running) → Delete Go to CodeBuild → Delete the 2 projects: student-management-frontend-build student-management-backend-build 2. Delete CloudFront Distribution Go to CloudFront → Select your distribution → Disable → Wait ~10–15 minutes → Delete (You cannot delete immediately if it’s still In Progress → you must Disable first) 3. Delete Amplify App (if using Amplify Console) Go to AWS Amplify → Select the app → Actions → Delete app → Type delete to confirm 4. Delete API Gateway Go to API Gateway → Select student-management-api (HTTP API) → Delete 5. Delete Lambda Function Go to Lambda → Select the function student-management-api → Actions → Delete 6. Delete AppSync API (if you created the real-time chat) Go to AppSync → Select student-management-chat → Delete 7. Delete Cognito User Pool Go to Cognito → User Pools → Select your pool → Delete user pool Note: If any user is still signed in, you must force delete or delete the users first.\n8. Delete DynamoDB Tables Go to DynamoDB → Tables → Delete the following 4 tables: student-management-users student-management-classes student-management-subjects student-management-notifications (If you have a Messages table for AppSync → delete it as well) 9. Delete WAF Web ACL Go to WAF \u0026amp; Shield → Web ACLs → Region Global (CloudFront) → Select student-management-waf → Delete 10. Delete Route53 Hosted Zone (if you created one) Go to Route53 → Hosted zones → Select your domain yourdomain.com → **Delete hosted zone` Only delete if you created a new hosted zone during the workshop — do NOT delete if it’s a real domain you\u0026rsquo;re using!\n11. Delete ACM Certificate (if created in us-east-1) Go to Certificate Manager → Region us-east-1 → Select the certificate → Delete 12. Delete S3 Buckets (Artifacts \u0026amp; Amplify if any) Delete the buckets: student-management-artifacts-{account-id} Amplify-generated buckets (usually named like amplify-...) Before deleting: Empty bucket → then Delete\n13. Delete CloudWatch Log Groups (optional, for account cleanliness) Go to CloudWatch → Log groups → Delete: /aws/lambda/student-management-api /aws/apigateway/... CodeBuild/CodePipeline log groups if desired 14. Delete IAM Roles/Policies (optional but recommended) Find and delete the roles you created: Lambda execution role CodePipeline/CodeBuild roles Amplify service roles (if any) After completing the steps above, your AWS account will no longer incur any charges from this workshop (except for a few remaining cents within the current billing cycle).\n"},{"uri":"https://sharonng1029.github.io/fcj-fall2025-internship-report/7-feedback/","title":"Sharing &amp; Feedback","tags":[],"description":"","content":"General Evaluation 1. Working Environment\nThe environment at FCJ is highly dynamic and values a spirit of ownership. The working atmosphere is professional yet comfortable enough for me to openly exchange ideas with mentors. However, the noise level when crowded can be distracting at times, but the policy allowing headphones has effectively solved this issue.\n2. Support from Mentor / Team Admin\nThe mentors are extremely dedicated and always available when support is needed. I highly appreciate that they encourage me to try and solve problems independently rather than just providing the answers immediately.\n3. Relevance between work and major\nThe assigned tasks have a progressive level of difficulty, which is very suitable for the roadmap of a 3rd or 4th-year student. I have had the opportunity to apply foundational knowledge of Programming and Computer Networking learned at university to a real-world Cloud environment.\n4. Learning opportunities \u0026amp; Skill development\nDuring the internship, I learned many new skills such as using project management tools, teamwork, and professional communication within a corporate environment. Mentors also shared a lot of practical experience, helping me better orient my future career path.\n5. Culture \u0026amp; Team Spirit\nFrom the beginning of the First Cloud Journey, I was very impressed by the community\u0026rsquo;s team spirit. Everyone respects one another; we work seriously but maintain a fun atmosphere. Support is given regardless of whether one is an intern or a full-time employee, which makes me feel like a true part of the collective.\n6. Policies / Benefits for Interns\nI particularly enjoy the Workshops/Events organized by AWS; these help me and other students access new knowledge and gain opportunities to network with seniors in the field. Additionally, the Hybrid working model provides favorable conditions for time flexibility and comfort.\nOther Questions What are you most satisfied with during the internship? I am most satisfied with the program\u0026rsquo;s policies and regulations, which create very favorable conditions for participants. Additionally, the friendliness and readiness of mentors to help and answer questions is a highlight.\nWhat do you think the company needs to improve for future interns? The documentation is very deep and extensive, so I was quite confused in the beginning. I hope the team can update the guidance to provide a more detailed direction/roadmap.\nIf you were to introduce this to friends, would you recommend interning here? Why? Definitely yes. This is an ideal place to experience work culture. The company organizes many events that provide both new knowledge and job opportunities for students. Especially, the mentors are all dedicated to answering questions and supporting students.\nProposals \u0026amp; Desires Do you have any suggestions to improve the internship experience? Since most interns are about to graduate, I suggest the team organize additional workshops/talkshows regarding Job Interviews, working experiences, or in-depth CV reviews. This would help interns review missing knowledge and feel more confident when applying for official positions at the company\nDo you want to continue this program in the future? Yes, I really hope to continue accompanying the First Cloud Journey program in the future.\nOther comments (feel free to share):\n"},{"uri":"https://sharonng1029.github.io/fcj-fall2025-internship-report/1-worklog/1.7-week7/","title":"Week 7 Worklog","tags":[],"description":"","content":"Week 7 Objectives: Finalize Project topic. Design detailed architecture (apply Well-Architected). Tasks to be carried out this week: Day Tasks Start Finish References 2 - Team meeting to review ideas one last time. 20/10/2025 20/10/2025 — 3 - Finalize project: \u0026ldquo;Serverless Student Management System\u0026rdquo;.\n- Reason: Cost-optimized, Scalable, Familiar. 21/10/2025 21/10/2025 — 4 - Draw detailed Architecture Diagram.\n- Review Frontend, Auth (Cognito), CDN (CloudFront). 22/10/2025 22/10/2025 — 5 - Research AppSync (GraphQL) for Realtime Chat.\n- Compare AppSync vs API Gateway + WebSocket. 23/10/2025 23/10/2025 AppSync Use Cases 6 - Midterm Review: Secure Architectures\n+ IAM, MFA, SCP\n+ Encryption (KMS, TLS/ACM)\n+ Security Groups, NACLs\n+ GuardDuty, Shield, WAF, Secrets Manager 24/10/2025 25/10/2025 IAM Best Practices\nAWS KMS\nSecurity Groups Week 7 Achievements: 1. Project Kickoff:\nFinalized topic and selected technologies (Serverless Stack). Completed the initial system architecture diagram. Understood the advantages of AppSync for realtime features. 2. Midterm Preparation:\nReviewed Secure Architectures topics systematically. Understood core security components: IAM, Encryption, Security Groups, GuardDuty, WAF. Implemented Well-Architected mindset into system design. "},{"uri":"https://sharonng1029.github.io/fcj-fall2025-internship-report/1-worklog/1.8-week8/","title":"Week 8 Worklog","tags":[],"description":"","content":"Week 8 Goals: Learn about Cost-Optimized Architectures. Balance midterm exam preparation and internship workload. Tasks for this week: Day Task Start Finish References 2 - Midterm Review: Resilient Architectures\n+ Multi-AZ, Multi-Region\n+ DR Strategies\n+ Auto Scaling, Route 53, Load Balancing\n+ Backup \u0026amp; Restore 27/10/2025 27/10/2025 Disaster Recovery\nAuto Scaling 3 - Midterm Review: High-Performing Architectures\n+ EC2 Auto Scaling, Lambda, Fargate\n+ S3, EFS, EBS\n+ Caching, CloudFront, Global Accelerator 28/10/2025 28/10/2025 Lambda Functions\nCloudFront\nS3 Performance 4 - Midterm Review: Cost-Optimized Architectures\n+ Cost Explorer, Budgets\n+ Savings Plans, Lifecycle Policies\n+ NAT Gateway Optimization, Storage Tiering\n- Review AWS Well-Architected 29/10/2025 29/10/2025 Cloud Financial Management 5 - General Review and finalize key AWS services. 30/10/2025 30/10/2025 AWS Well-Architected Framework 6 - Company Midterm Exam. 31/10/2025 31/10/2025 — Week 8 Outcomes: 1. AWS Solutions Architect Knowledge:\nCompleted comprehensive review of the four architecture pillars: Security, Resilience, Performance, Cost Optimization. Gained deeper understanding of the AWS Well-Architected Framework and how to apply it to real-world cases. Mastered core services: EC2, S3, IAM, RDS, VPC, Lambda, CloudWatch, CloudFront and how they work together. Consolidated knowledge on DR Strategies, Auto Scaling, Load Balancing, Caching, and Cost Optimization. 2. Time Management \u0026amp; Midterm Results:\nSuccessfully balanced studying for exams and project progress. Although the exam result was not as expected, fully ready to return to the project. "},{"uri":"https://sharonng1029.github.io/fcj-fall2025-internship-report/1-worklog/1.9-week9/","title":"Week 9 Worklog","tags":[],"description":"","content":"Week 9 Goals: Business analysis. Write the project Proposal. Tasks for this week: Day Task Start Finish References 2 - Analyze User Stories (Admin, Student).\n- Identify Core Features: Student CRUD, Chat, Ranking.\n- Create detailed Use Case list. 03/11/2025 03/11/2025 — 3 - Write Proposal: Problem Statement \u0026amp; Solution.\n- Estimate costs using AWS Pricing Calculator.\n- Analyze benefits of Serverless architecture. 04/11/2025 04/11/2025 AWS Pricing Calculator 4 - Draw Business Flowcharts (Login flow, Submission flow).\n- Design ERD for DynamoDB Schema.\n- Identify required API endpoints. 05/11/2025 05/11/2025 — 5 - Team Proposal Review.\n- Finalize Tech Stack: DynamoDB, Lambda, S3, Cognito, SES\u0026hellip;\n- Assign responsibilities to team members. 06/11/2025 06/11/2025 — 6 - Finalize Proposal document. 07/11/2025 07/11/2025 — Week 9 Outcomes: 1. Completed Proposal Document:\nProposal includes 3 main sections: Problem Statement, Solution Architecture, Cost Estimation. Operational costs calculated in detail using AWS Pricing Calculator, proving Serverless is more cost-efficient than traditional servers. Tech stack proposed: DynamoDB (Database), Lambda (Backend Logic), API Gateway (REST API), Cognito (Authentication), S3 (Frontend Hosting). 2. Detailed System Analysis:\nUse Cases \u0026amp; User Stories: Fully listed for Admin, Lecturer, and Student roles. Business Flowcharts: Created for Login (Cognito) and Assignment Submission flow. Database Schema: Designed DynamoDB ERD following Single Table Design. API Endpoints: Identified all required endpoints for frontend integration. "},{"uri":"https://sharonng1029.github.io/fcj-fall2025-internship-report/1-worklog/1.10-week10/","title":"Week 10 Worklog","tags":[],"description":"","content":"Week 10 Goals: Submit Proposal. Design UI/UX \u0026amp; Explore AI/ML. Tasks for this week: Day Task Start Finish References 2 - Submit Project Proposal. 10/11/2025 10/11/2025 — 3 - Draft UI Wireframes (Login, Dashboard, Chat).\n- Design Mobile Responsive Layout. 11/11/2025 11/11/2025 — 4 - Choose UI Library: Tailwind CSS + Chakra UI v3.\n- Setup test environment. 12/11/2025 12/11/2025 Tailwind Docs\nChakra UI Docs 5 - EVENT: Attend AWS Cloud Mastery Series #1 – AI/ML \u0026amp; Generative AI. 13/11/2025 13/11/2025 Event Link 6 - Propose new Ranking/Suggestion feature using Amazon Personalize.\n- Study Amazon Personalize. 14/11/2025 14/11/2025 Amazon Personalize Week 10 Outcomes: 1. Proposal Submission Completed:\nFully submitted final Proposal on time. Received positive feedback from mentor regarding Serverless architecture and cost estimation. 2. UI/UX Design Completed:\nFinished Wireframe for Login, Dashboard, and Chat interfaces. Designed Responsive UI for mobile accessibility. Finalized frontend stack: Tailwind CSS + Chakra UI v3. 3. Expanded AI/ML Knowledge:\nAttended AWS Cloud Mastery Series #1, understanding SageMaker, Bedrock, Personalize. Explored Amazon Personalize to propose intelligent Ranking/Suggestion features. Learned how Personalize integrates with Lambda and DynamoDB. "},{"uri":"https://sharonng1029.github.io/fcj-fall2025-internship-report/1-worklog/1.11-week11/","title":"Week 11 Worklog","tags":[],"description":"","content":"Week 11 Goals: Setup Frontend Project. Integrate Authentication (Cognito). Join DevOps event. Tasks for this week: Day Task Start Finish References 2 - EVENT: Attend AWS Cloud Mastery Series #2 – DevOps on AWS.\n- Explore CI/CD (CodePipeline). 18/11/2025 18/11/2025 Event Link 3 - Design Database Schema (DynamoDB JSON).\n- Send schema to Backend team. 19/11/2025 19/11/2025 DynamoDB Best Practices 4 - Initialize React + TypeScript project (Vite).\n- Configure Tailwind, ESLint, and Git repo. 20/11/2025 20/11/2025 Vite Guide\nTS Handbook 5 - Build Login Page UI.\n- Add validation using React Hook Form + Zod. 21/11/2025 21/11/2025 RHF Docs\nZod Docs 6 - Configure Amazon Cognito (User Pool).\n- Integrate Amplify Auth.\n- Successfully connect Login API (JWT Token). 22/11/2025 22/11/2025 Amplify Auth Week 11 Outcomes: 1. DevOps Knowledge:\nLearned CI/CD tools: CodePipeline, CodeBuild, CodeDeploy. Understood automated deployment workflows. Planned to implement CI/CD for deploying Frontend to S3 + CloudFront. 2. Frontend Project Setup:\nSuccessfully setup React + TypeScript + Vite. Configured Tailwind CSS and ESLint. Created Git repository with branch standards (main, develop, feature). 3. Authentication Development:\nBuilt Login UI with validation (RHF + Zod). Configured Cognito User Pool (password policy, email verification). Integrated Amplify Auth. Successfully authenticated Login API and retrieved JWT token. 4. Security Knowledge:\nUnderstood Authentication flow: React ↔ Cognito ↔ Backend (Lambda + API Gateway). Applied Secure Architecture Best Practices. Learned how to handle JWT token securely. "},{"uri":"https://sharonng1029.github.io/fcj-fall2025-internship-report/1-worklog/1.12-week12/","title":"Week 12 Worklog","tags":[],"description":"","content":"Week 12 Goals: Develop Admin Dashboard UI. Learn advanced Security (WAF, Shield). Tasks for this week: Day Task Start Finish References 2 - Build Admin Layout (Sidebar, Header).\n- Develop Reusable Components. 24/11/2025 25/11/2025 React Component Patterns 3 - Build Dashboard Overview.\n- Build Student Management screen (Table, Pagination). 26/11/2025 27/11/2025 — 4 - Complete UI (Responsive).\n- Finish Admin interface using Mock data. 28/11/2025 28/11/2025 — 5 - EVENT: Attend AWS Cloud Mastery Series #3 – Cloud Security Best Practices. 29/11/2025 29/11/2025 Event Link 6 - Refactor code, optimize performance.\n- Prepare for API integration. 30/11/2025 30/11/2025 React Performance Week 12 Outcomes: 1. Admin Dashboard UI:\nCompleted Admin Layout: Sidebar + Header. Built Dashboard Overview with metrics and charts. Built Student Management: Table, Pagination, Search/Filter, CRUD UI. Fully Responsive design for laptop/tablet/mobile. 2. Component Architecture \u0026amp; Code Quality:\nBuilt reusable components. Refactored code and improved folder structure. Used mock data for UI testing. 3. Advanced AWS Security Learning:\nLearned about AWS WAF and AWS Shield. Understood protection against SQL Injection, XSS, CSRF. Learned WAF rule configuration and rate limiting. Planned to integrate WAF with CloudFront. "},{"uri":"https://sharonng1029.github.io/fcj-fall2025-internship-report/1-worklog/1.13-week13/","title":"Week 13 Worklog","tags":[],"description":"","content":"Week 13 Objectives: Integrate Backend (API Gateway). Deploy CloudFront + WAF and Route53 (Custom Domain). Tasks to Execute This Week: Day Task Start Finish References 2 - Connect API Gateway (REST).\n- Handle CORS issues. 02/12/2025 02/12/2025 CORS in API Gateway Axios Documentation 3 - Integrate Student CRUD:\n+ Create (Add new student)\n+ Read (Get list/details)\n+ Update (Update information)\n+ Delete (Remove student)\n- Handle loading/error states on the UI. 03/12/2025 03/12/2025 React Query Error Handling Best Practices 4 Deploy CloudFront + WAF.\n- Create WAF Web ACL with security rules.\n- Create CloudFront Distribution.\n- Add API Gateway as an Origin. 04/12/2025 04/12/2025 AWS WAF CloudFront Distribution 5 - Configure Route53 (Custom Domain).\n- Create DNS Records for the domain.\n- Configure SSL Certificate with ACM (AWS Certificate Manager). 05/12/2025 05/12/2025 Route 53 DNS ACM Certificate 6 - Refactor Frontend code.\n- Optimize Performance (lazy loading, memoization).\n- Write code documentation. 06/12/2025 06/12/2025 React Performance Code Documentation Week 13 Achievements: 1. Successfully connected API:\nIntegrated Frontend with API Gateway built by the Backend team. Resolved CORS issues by working directly with the Backend team. Built API service with Axios, including automatic JWT Token injection. Implemented loading spinner and error notifications for API calls. 2. Completed Student CRUD Interface:\nBuilt add/edit student form with validation. Displayed student list using a table with pagination and search. Implemented student deletion with confirmation modal. Used React Query for data management and auto-refresh after mutations. 3. Deployed CloudFront + WAF:\nCreated WAF Web ACL with essential security rules (SQL Injection, XSS, Rate Limiting). Created CloudFront Distribution for content delivery. Added API Gateway as an Origin in CloudFront. Configured appropriate Cache Behavior for API requests. 4. Configured Route53 and SSL:\nCreated Hosted Zone for custom domain. Configured DNS Records (A Record, CNAME) pointing to CloudFront. Requested SSL Certificate from ACM for the domain. Attached certificate to the CloudFront Distribution. Successfully tested accessing the system via HTTPS through the custom domain. 5. Learned:\nHow to integrate Frontend with REST API. Understanding CDN and how CloudFront optimizes content delivery. Configuring WAF to protect applications from common attacks. Managing DNS using Route53 and configuring SSL Certificates with ACM. Collaborating with Backend team to resolve CORS and test End-to-End flows. "},{"uri":"https://sharonng1029.github.io/fcj-fall2025-internship-report/categories/","title":"Categories","tags":[],"description":"","content":""},{"uri":"https://sharonng1029.github.io/fcj-fall2025-internship-report/tags/","title":"Tags","tags":[],"description":"","content":""}]